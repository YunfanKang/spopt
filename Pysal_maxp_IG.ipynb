{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bf916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2763e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import geopandas\n",
    "import libpysal\n",
    "import numpy\n",
    "path = \"notebooks/data/LACounty/La_county_noisland.shp\"\n",
    "lacity = geopandas.read_file(path)\n",
    "lacity.plot(column = 'pop2010', figsize = (12, 8), edgecolor = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e78fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = libpysal.weights.Queen.from_dataframe(lacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ce842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top_n = 2\n",
    "sum_attr = 'pop2010'\n",
    "sum_low = 20000.0\n",
    "dis_attr = 'households'\n",
    "RANDOM_SEED = 123456\n",
    "numpy.random.seed(RANDOM_SEED)\n",
    "model = MaxPHeuristic(lacity, w, dis_attr, sum_attr, sum_low, top_n, verbose = True, tarjan_flag = False)\n",
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "top_n = 2\n",
    "sum_attr = 'pop2010'\n",
    "sum_low = 20000.0\n",
    "dis_attr = 'households'\n",
    "RANDOM_SEED = 123456\n",
    "numpy.random.seed(RANDOM_SEED)\n",
    "model = MaxPHeuristic(lacity, w, dis_attr, sum_attr, sum_low, top_n, verbose = True, tarjan_flag = True)\n",
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaxPHeuristic(lacity, w, dis_attr, sum_attr, sum_low, top_n, max_iterations_construction= 999, verbose = True, tarjan_flag = True)\n",
    "model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21166025",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp(lacity, w, dis_attr, sum_attr, sum_low, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea59223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#areas = np.array([747, 625, 884, 614, 623])\n",
    "#areas = np.array([ 216, 1270, 1272,  217,  218,  220,  367]) #1\n",
    "areas = np.array([1546, 1153, 2038, 1543, 1544, 1545,  801,  226,  799,  214])\n",
    "areas = np.array([1046, 1760, 1045, 1047, 1048, 1642, 1755, 1959])\n",
    "areas = np.array([ 216, 1270, 1272,  217,  218,  220,  367])\n",
    "from collections import defaultdict\n",
    "def dfs(\n",
    "    area_index,\n",
    "    region_graph,\n",
    "    visited,\n",
    "    discovery_time,\n",
    "    low,\n",
    "    parent,\n",
    "    time,\n",
    "    articulation_points\n",
    "):\n",
    "    visited[area_index] = True\n",
    "    discovery_time[area_index] = time\n",
    "    low[area_index] = time\n",
    "    children = 0\n",
    "    for neighbor_index in region_graph[area_index]:\n",
    "        if not visited[neighbor_index]:\n",
    "            parent[neighbor_index] = area_index\n",
    "            children += 1\n",
    "            dfs(neighbor_index, region_graph, visited, discovery_time, low, parent, time + 1, articulation_points)\n",
    "            low[area_index] = min(low[area_index], low[neighbor_index])\n",
    "\n",
    "            if parent[area_index] == -1 and children > 1:\n",
    "                articulation_points.add(area_index)\n",
    "                #print(\"Area\" , area_index, \" added as root\")\n",
    "            elif parent[area_index] != -1 and low[neighbor_index] >= discovery_time[area_index]:\n",
    "                articulation_points.add(area_index)\n",
    "                #print(\"Area\" , area_index, \" added as articluation \", parent[area_index])\n",
    "        elif neighbor_index != parent[area_index]:\n",
    "            low[area_index] = min(low[area_index], discovery_time[neighbor_index])\n",
    "def get_articulation_points(\n",
    "    areas_in_region,\n",
    "    weight_sparse\n",
    "): \n",
    "    \"\"\"Get the articulation areas out of a region.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    areas_in_region : array, required\n",
    "        All the areas in the regions\n",
    "\n",
    "    weight_sparse : dict, required\n",
    "        A dictionary with key as area ID and value as a list of \n",
    "        neighbor areas.\n",
    "\n",
    "    visited : array, required\n",
    "        An array that indicating whether each area has been visited\n",
    "\n",
    "    discovery_time : array, required\n",
    "        An array of the discovery time of the areas during the BFS traversal.\n",
    "\n",
    "    low :array, required\n",
    "        An array of the topmost reachable ancestor for each area in the DFS\n",
    "\n",
    "    parent : array, required\n",
    "        The array of the parent of each area in the DFS traversal\n",
    "    time : int\n",
    "        The time stamp of the DFS traversal\n",
    "\n",
    "    articulation_points : list\n",
    "        a list of atriculation area units which will cause the number of connected components to increase once removed.\n",
    "\n",
    "    \"\"\"\n",
    "    edges_with_index = weight_sparse[areas_in_region, :][:, areas_in_region]\n",
    "    region_graph = defaultdict(list)\n",
    "    cx = coo_matrix(edges_with_index)  \n",
    "    #print(cx)\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "        region_graph[i].append(j)\n",
    "    \n",
    "    visited = False * areas_in_region\n",
    "    discovery_time = [-1] * areas_in_region.size\n",
    "    low = [-1] * areas_in_region.size\n",
    "    parent = [-1] * areas_in_region.size\n",
    "    #print(parent)\n",
    "    time = 0\n",
    "    articulation_points = set()\n",
    "    for area_index in range(areas_in_region.size):\n",
    "        if not visited[area_index]:\n",
    "            dfs(area_index, region_graph, visited, discovery_time, low, parent, time, articulation_points)\n",
    "    return list(articulation_points)\n",
    "\n",
    "\n",
    "print(get_articulation_points(areas, w.sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_construction_phase(\n",
    "    arr,\n",
    "    attr,  # noqa ARG001\n",
    "    deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    weight,\n",
    "    spatialThre,\n",
    "    random_assign_choice,\n",
    "    max_it=99,\n",
    "):\n",
    "    \"\"\"Construct feasible solutions for max-p-regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    arr : array, required\n",
    "        An array of index of area units.\n",
    "\n",
    "    attr : array, required\n",
    "        An array of the values of the attributes.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data.\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    random_assign_choice : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    max_it : int\n",
    "        Maximum number of iterations. Default is 999.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    real_values : list\n",
    "        ``realmaxpv``, ``realLabelsList``\n",
    "\n",
    "    \"\"\"\n",
    "    labels_list = []\n",
    "    pv_list = []\n",
    "    max_p = 0\n",
    "    maxp_labels = None\n",
    "    maxp_regionList = None\n",
    "    maxp_regionSpatialAttr = None\n",
    "\n",
    "    for _ in range(max_it):\n",
    "        labels = [-2] * len(threshold_array)\n",
    "        for i in deconstruct_areas:\n",
    "            labels[i] = 0\n",
    "        C = 0\n",
    "        regionSpatialAttr = {}\n",
    "        enclave = []\n",
    "        regionList = {}\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        labeledID = []\n",
    "        #print(\"Iterateion \" , _)\n",
    "        failureCount = 0\n",
    "        \n",
    "        for arr_index in range(0, len(threshold_array)):\n",
    "            P = arr[arr_index]\n",
    "            if labels[P] != 0:\n",
    "                continue\n",
    "\n",
    "            NeighborPolys = deepcopy(weight.neighbors[P])\n",
    "\n",
    "            if len(NeighborPolys) == 0:\n",
    "                labels[P] = -1\n",
    "            else:\n",
    "                C += 1\n",
    "                labeledID, spatialAttrTotal = partial_grow_cluster_for_poly(\n",
    "                    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "                )\n",
    "                \n",
    "                if spatialAttrTotal < spatialThre:\n",
    "                    #print(\"Construction failed for \", P)\n",
    "                    failureCount += 1\n",
    "                    C -= 1\n",
    "                    enclave.extend(labeledID)\n",
    "                else:\n",
    "                    regionList[C] = labeledID\n",
    "                    regionSpatialAttr[C] = spatialAttrTotal\n",
    "        #print(\"Failure count for iteration \", _, \" is \" , failureCount)\n",
    "        num_regions = len(regionList)\n",
    "\n",
    "        for i, _l in enumerate(labels):\n",
    "            if _l == -1:\n",
    "                enclave.append(i)\n",
    "\n",
    "        if num_regions < max_p:\n",
    "            continue\n",
    "        else:\n",
    "            max_p = num_regions\n",
    "            maxp_labels, maxp_regionList, maxp_regionSpatialAttr = assign_enclave(\n",
    "                enclave,\n",
    "                labels,\n",
    "                regionList,\n",
    "                regionSpatialAttr,\n",
    "                threshold_array,\n",
    "                weight,\n",
    "                distance_matrix,\n",
    "                random_assign=random_assign_choice,\n",
    "            )\n",
    "            pv_list.append(max_p)\n",
    "            labels_list.append([maxp_labels, maxp_regionList, maxp_regionSpatialAttr])\n",
    "    realLabelsList = []\n",
    "    realmaxpv = max(pv_list)\n",
    "    for ipv, pv in enumerate(pv_list):\n",
    "        if pv == realmaxpv:\n",
    "            realLabelsList.append(labels_list[ipv])\n",
    "\n",
    "    real_values = [realmaxpv, realLabelsList]\n",
    "    return real_values\n",
    "\n",
    "def partial_grow_cluster_for_poly(\n",
    "    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "):\n",
    "    \"\"\"Grow one region until threshold constraint is satisfied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    labels : list, required\n",
    "        A list of current region labels\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    P : int, required\n",
    "        The index of current area unit\n",
    "\n",
    "    NeighborPolys : list, required\n",
    "        The neighbors of current area unit\n",
    "\n",
    "    C : int, required\n",
    "        The index of current region\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    cluster_info : tuple\n",
    "        ``labeledID``, ``spatialAttrTotal``\n",
    "\n",
    "    \"\"\"\n",
    "    labels[P] = C\n",
    "    labeledID = [P]\n",
    "    spatialAttrTotal = threshold_array[P]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < len(NeighborPolys):\n",
    "        if spatialAttrTotal >= spatialThre:\n",
    "            break\n",
    "        Pn = NeighborPolys[i]\n",
    "\n",
    "        if labels[Pn] == 0:\n",
    "            labels[Pn] = C\n",
    "            labeledID.append(Pn)\n",
    "            spatialAttrTotal += threshold_array[Pn]\n",
    "            if spatialAttrTotal < spatialThre:\n",
    "                PnNeighborPolys = weight.neighbors[Pn]\n",
    "                for pnn in PnNeighborPolys:\n",
    "                    if pnn not in NeighborPolys:\n",
    "                        NeighborPolys.append(pnn)\n",
    "        i += 1\n",
    "\n",
    "    cluster_info = labeledID, spatialAttrTotal\n",
    "    return cluster_info\n",
    "\n",
    "\n",
    "def assign_enclave(\n",
    "    enclave,\n",
    "    labels,\n",
    "    regionList,\n",
    "    regionSpatialAttr,\n",
    "    threshold_array,\n",
    "    weight,\n",
    "    distance_matrix,\n",
    "    random_assign=1,\n",
    "):\n",
    "    \"\"\"Assign the enclaves to the regions identified in the region growth phase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    enclave : list, required\n",
    "        A list of enclaves.\n",
    "\n",
    "    labels : list, required\n",
    "        A list of region labels for area units.\n",
    "\n",
    "    regionList : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    regionSpatialAttr : dict, required\n",
    "        A dictionary with key as region ID and value as the total\n",
    "        spatial extensive attribute of the region.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    random_assign : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    region_info : list\n",
    "        Deep copies of ``labels``, ``regionList``, and ``regionSpatialAttr``\n",
    "\n",
    "    \"\"\"\n",
    "    enclave_index = 0\n",
    "    while len(enclave) > 0:\n",
    "        #print(\"enclave index: \", enclave_index)\n",
    "        #print(\"enclave list length: \", len(enclave))\n",
    "        ec = enclave[enclave_index]\n",
    "        ecNeighbors = weight.neighbors[ec]\n",
    "        assignedRegion = 0\n",
    "        ecNeighborsList = []\n",
    "\n",
    "        for ecn in ecNeighbors:\n",
    "            if ecn in enclave or labels[ecn] == -2:\n",
    "                continue\n",
    "            rm = np.array(regionList[labels[ecn]])\n",
    "            totalDistance = distance_matrix[ec, rm].sum()\n",
    "            ecNeighborsList.append((ecn, totalDistance))\n",
    "        ecNeighborsList = sorted(ecNeighborsList, key=lambda tup: tup[1])\n",
    "        top_num = min([len(ecNeighborsList), random_assign])\n",
    "        if top_num > 0:\n",
    "            ecn_index = np.random.randint(top_num)\n",
    "            assignedRegion = labels[ecNeighborsList[ecn_index][0]]\n",
    "\n",
    "        if assignedRegion == 0:\n",
    "            enclave_index += 1\n",
    "        else:\n",
    "            labels[ec] = assignedRegion\n",
    "            regionList[assignedRegion].append(ec)\n",
    "            regionSpatialAttr[assignedRegion] += threshold_array[ec]\n",
    "            del enclave[enclave_index]\n",
    "            enclave_index = 0\n",
    "\n",
    "    region_info = [deepcopy(labels), deepcopy(regionList), deepcopy(regionSpatialAttr)]\n",
    "    return region_info\n",
    "\n",
    "def checkResult(\n",
    "        labels,\n",
    "        regionAreaDic,\n",
    "        regionAttrDic,\n",
    "        threshold_array\n",
    "):\n",
    "    status = 0\n",
    "    realAttrDic = dict()\n",
    "    for regionId in regionAreaDic:\n",
    "        regionAttrTotal = 0\n",
    "        for area in regionAreaDic[regionId]:\n",
    "            regionAttrTotal += threshold_array[area]\n",
    "            if labels[area] != regionId:\n",
    "                print(\"Area \", area, \" is labled in region (\", labels[area], \") but in the list of (\", regionId, \")\")\n",
    "                status = -1\n",
    "        if regionAttrTotal != regionAttrDic[regionId]:\n",
    "                print(\"Region (\", regionId, \") attribute does not match\")\n",
    "                status = -2\n",
    "    print(\"Checking finished with status: \", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with p:  383\n",
      "Construction time:  0.11750030517578125\n",
      "Ends with:  421\n",
      "Reconstruction time:  21.577794313430786\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "gdf = lacity\n",
    "attr = np.atleast_2d(gdf[dis_attr].values)\n",
    "if attr.shape[0] == 1: \n",
    "    attr = attr.T\n",
    "threshold_array = gdf[sum_attr].values\n",
    "distance_matrix = squareform(pdist(attr, metric=\"cityblock\"))\n",
    "n, k = attr.shape\n",
    "arr = np.arange(n)\n",
    "iterated_greedy_construction(arr,\n",
    "    attr,  # noqa ARG001\n",
    "    #deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    w,\n",
    "    sum_low,\n",
    "    top_n,\n",
    "    initial_it = 1,\n",
    "    deconstruct_it = 1000,\n",
    "    reconst_it = 99,\n",
    "    disturbance_intensity = 0.01,\n",
    "    max_it=1,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with p:  377\n",
      "Construction time:  0.07566595077514648\n",
      "Ends with:  377\n",
      "Reconstruction time:  17.271681547164917\n",
      "Start with p:  390\n",
      "Construction time:  0.052764177322387695\n",
      "Ends with:  422\n",
      "Reconstruction time:  23.35978603363037\n",
      "Start with p:  387\n",
      "Construction time:  0.06682872772216797\n",
      "Ends with:  421\n",
      "Reconstruction time:  26.96209955215454\n",
      "Start with p:  381\n",
      "Construction time:  0.05445528030395508\n",
      "Ends with:  418\n",
      "Reconstruction time:  25.16695284843445\n",
      "Start with p:  385\n",
      "Construction time:  0.05081915855407715\n",
      "Ends with:  413\n",
      "Reconstruction time:  28.73438048362732\n",
      "Start with p:  377\n",
      "Construction time:  0.06311988830566406\n",
      "Ends with:  415\n",
      "Reconstruction time:  33.73021841049194\n",
      "Start with p:  381\n",
      "Construction time:  0.05797290802001953\n",
      "Ends with:  410\n",
      "Reconstruction time:  36.522923707962036\n",
      "Start with p:  377\n",
      "Construction time:  0.057202816009521484\n",
      "Ends with:  406\n",
      "Reconstruction time:  39.89541029930115\n",
      "Start with p:  385\n",
      "Construction time:  0.05729246139526367\n",
      "Ends with:  408\n",
      "Reconstruction time:  43.691617488861084\n",
      "Start with p:  369\n",
      "Construction time:  0.059371232986450195\n",
      "Ends with:  405\n",
      "Reconstruction time:  46.395819664001465\n"
     ]
    }
   ],
   "source": [
    "for di in range (0, 10):\n",
    "    iterated_greedy_construction(arr,\n",
    "        attr,  # noqa ARG001\n",
    "        #deconstruct_areas,\n",
    "        threshold_array,\n",
    "        distance_matrix,\n",
    "        w,\n",
    "        sum_low,\n",
    "        top_n,\n",
    "        initial_it = 1,\n",
    "        deconstruct_it = 1000,\n",
    "        reconst_it = 99,\n",
    "        disturbance_intensity = di/100,\n",
    "        max_it=1,\n",
    "        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(c_rl_list[0][2].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(threshold_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irl, rl in enumerate(rl_list):\n",
    "        label, regionList, regionSpatialAttr = rl\n",
    "        print(regionSpatialAttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lacity[\"maxp_new\"] = rl_list[0][0]\n",
    "lacity[[\"maxp_new\",  \"pop2010\"]].groupby(by=\"maxp_new\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hop_neighbor_regions(\n",
    "    regionIds,\n",
    "    labels,\n",
    "    weight\n",
    "):\n",
    "    one_hop_neighbor_set = set()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in regionIds:\n",
    "            neighbor_list = [labels[j] for j in weight.neighbors[i]]\n",
    "            one_hop_neighbor_set.update(neighbor_list)\n",
    "    return one_hop_neighbor_set\n",
    "def get_deconstruct_areas(\n",
    "    regionIds,\n",
    "    labels\n",
    "):\n",
    "    deconstruct_areas = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in regionIds:\n",
    "            deconstruct_areas.append(i)\n",
    "    return deconstruct_areas\n",
    "def iterated_greedy_construction(\n",
    "    arr,\n",
    "    attr,  # noqa ARG001\n",
    "    #deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    w,\n",
    "    sum_low,\n",
    "    top_n,\n",
    "    initial_it = 1,\n",
    "    deconstruct_it = 1000,\n",
    "    reconst_it = 99,\n",
    "    disturbance_intensity = 5,\n",
    "    max_it=1,\n",
    "    verbose = False\n",
    "):\n",
    "    cStartTime = time.time()\n",
    "    c_max_p, c_rl_list = construction_phase(\n",
    "        arr,\n",
    "        attr,  # noqa ARG001\n",
    "        #deconstruct_areas,\n",
    "        threshold_array,\n",
    "        distance_matrix,\n",
    "        w,\n",
    "        sum_low,\n",
    "        top_n,\n",
    "        max_it=initial_it,\n",
    "    )\n",
    "    cEndTime = time.time()\n",
    "    if verbose:\n",
    "        print(\"Start with p: \", c_max_p)\n",
    "        print(\"Construction time: \", cEndTime - cStartTime)\n",
    "    #print(c_rl_list[0][1])\n",
    "    #dec_it = 1000\n",
    "    #dec_count = 5\n",
    "    for i in range(deconstruct_it):\n",
    "        \n",
    "        center_region = []\n",
    "        for i in range(disturbance_intensity):\n",
    "            center_region.append(numpy.random.randint(1, c_max_p))\n",
    "        one_hop_regions = get_one_hop_neighbor_regions(center_region, c_rl_list[0][0], w)\n",
    "        #print(\"Original deconstructed p: \", len(one_hop_regions), one_hop_regions)\n",
    "        deconstruct_areas = get_deconstruct_areas(one_hop_regions, c_rl_list[0][0])\n",
    "\n",
    "        deconstruct_threshold_values = [threshold_array[i] for i in deconstruct_areas]\n",
    "        #print(\"Reconstruct \", deconstruct_areas)\n",
    "        #print(\"Threshold attrs \", deconstruct_threshold_values)\n",
    "        #print(\"Threshold \", sum_low)\n",
    "        #print(\"Total attr deconstructed \", sum(deconstruct_threshold_values))\n",
    "\n",
    "        max_p, rl_list = partial_construction_phase(\n",
    "            arr,\n",
    "            attr,  # noqa ARG001\n",
    "            deconstruct_areas,\n",
    "            threshold_array,\n",
    "            distance_matrix,\n",
    "            w,\n",
    "            sum_low,\n",
    "            top_n,\n",
    "            max_it=9,\n",
    "        )\n",
    "        #print(\"Reconstructed p: \", max_p)\n",
    "        #print(len(rl_list[0][1]))\n",
    "        #print(\"Better? \", max_p > len(one_hop_regions))\n",
    "        dec_region_value = 0\n",
    "        dec_area_value = 0\n",
    "        #print(c_rl_list[0][2])\n",
    "        #checkResult(c_rl_list[0][0], c_rl_list[0][1], c_rl_list[0][2], threshold_array)\n",
    "        #print(c_rl_list[0][2])\n",
    "        for r in one_hop_regions:\n",
    "            dec_region_value += c_rl_list[0][2][r]\n",
    "        for a in deconstruct_areas:\n",
    "            dec_area_value += threshold_array[a]\n",
    "        #print(\"Valid?\", dec_region_value, \" ? \", dec_area_value , \" ? \",sum(rl_list[0][2].values()))\n",
    "        #print(rl_list[0][1])\n",
    "        #print(c_max_p)\n",
    "        '''print(c_rl_list[0][2])'''\n",
    "        if(max_p > len(one_hop_regions)):\n",
    "            p_difference = max_p - len(one_hop_regions)\n",
    "            \n",
    "            for i in range(1, len(one_hop_regions) + 1):\n",
    "                #print(i)\n",
    "                #print(list(one_hop_regions)[i-1])\n",
    "                #print(i)\n",
    "                #print(rl_list[0][1][i])\n",
    "                for area in rl_list[0][1][i]:\n",
    "                    c_rl_list[0][0][area] = list(one_hop_regions)[i-1]\n",
    "                c_rl_list[0][1][list(one_hop_regions)[i-1]] = rl_list[0][1][i]\n",
    "                c_rl_list[0][2][list(one_hop_regions)[i-1]] = rl_list[0][2][i]\n",
    "            for i in range(len(one_hop_regions) + 1, max_p + 1):\n",
    "                new_regionId = c_max_p + i - len(one_hop_regions)\n",
    "                #print(\"New region: \", new_regionId)\n",
    "                #print(rl_list[0][1][i + len(one_hop_regions)])\n",
    "                for area in rl_list[0][1][i]:\n",
    "                    c_rl_list[0][0][area] = new_regionId\n",
    "                c_rl_list[0][1][new_regionId] = rl_list[0][1][i]\n",
    "                c_rl_list[0][2][new_regionId] = rl_list[0][2][i]\n",
    "            c_max_p += p_difference\n",
    "    rEndTime = time.time()\n",
    "    if verbose:\n",
    "        print(\"Ends with: \", c_max_p)\n",
    "        print(\"Reconstruction time: \", rEndTime - cEndTime)\n",
    "#def update_partition(\n",
    "    \n",
    "#):\n",
    "#print(get_deconstruct_areas(get_one_hop_neighbor_regions([1], model.labels_, w), model.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [1]\n",
    "one_hop_neighbor_set = set()\n",
    "deconstruct_areas = []\n",
    "for i in range(len(model.labels_)):\n",
    "    if model.labels_[i] in target:\n",
    "        deconstruct_areas.append(i)\n",
    "print(deconstruct_areas)\n",
    "for da in deconstruct_areas:\n",
    "    print(\"Neighbors for \", da, \": \", w.neighbors[da])\n",
    "    neighbor_list = [model.labels_[i] for i in w.neighbors[da]]\n",
    "    print(\"Their region labels: \", neighbor_list)\n",
    "    one_hop_neighbor_set.update(neighbor_list)\n",
    "print(one_hop_neighbor_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = max(model.labels_)\n",
    "area_count = 0\n",
    "#total_attr = 0\n",
    "region_list = []\n",
    "attr_list = []\n",
    "area_checkList = [0] * len(model.labels_)\n",
    "for i in range(1, max_label+1):\n",
    "    region_area = []\n",
    "    region_attr = 0\n",
    "    for j in range(len(model.labels_)):\n",
    "        if model.labels_[j] == i:\n",
    "            region_area.append(j)\n",
    "            area_checkList[j] += 1\n",
    "            region_attr += threshold_array[j]\n",
    "    region_list.append(region_area)\n",
    "    attr_list.append(region_attr)\n",
    "    #total_attr += region_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(threshold_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_checkList == [1] * len(area_checkList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm with Greedy construction\n",
    "### Multiple constructions to get the set of INITIAL partitions with the maximum P value\n",
    "### Genetic to improve the heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated Local search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Iterated Max-p regions algorithm.\n",
    "\n",
    "The greedy construction phase is modified to adopt the iterated greedy framework.\n",
    "\n",
    "Source: Wei, Ran, Sergio J. Rey, and Elijah Knaap (2020) \"Efficient\n",
    "regionalization for spatially explicit neighborhood delineation.\" International\n",
    "Journal of Geographical Information Science. Accepted 2020-04-12.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "__author__ = [\"Ran Wei\", \"Serge Rey\", \"Elijah Knaap\"]\n",
    "__email__ = \"sjsrey@gmail.com\"\n",
    "\n",
    "from copy import deepcopy\n",
    "import spopt\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from collections import defaultdict\n",
    "\n",
    "from spopt.BaseClass import BaseSpOptHeuristicSolver\n",
    "from spopt.region.base import modify_components\n",
    "import time\n",
    "ITERCONSTRUCT = 100\n",
    "ITERSA = 10\n",
    "\n",
    "\n",
    "def iterated_maxp(\n",
    "    gdf,\n",
    "    w,\n",
    "    attrs_name,\n",
    "    threshold_name,\n",
    "    threshold,\n",
    "    top_n,\n",
    "    max_iterations_construction=ITERCONSTRUCT,\n",
    "    max_iterations_sa=ITERSA,\n",
    "    verbose=False,\n",
    "    policy=\"single\",\n",
    "    initial_it = 1,\n",
    "    deconstruct_it = 1000,\n",
    "    reconst_it = 99,\n",
    "    disturbance_intensity = 0.05,\n",
    "    max_it=1,\n",
    "    tarjan_flag = True\n",
    "):\n",
    "    \"\"\"The max-p-regions involves the aggregation of n areas into an unknown maximum\n",
    "     number of homogeneous regions, while ensuring that each region is contiguous and\n",
    "     satisfies a minimum threshold value imposed on a predefined spatially extensive\n",
    "    attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    gdf : geopandas.GeoDataFrame, required\n",
    "        Geodataframe containing original data\n",
    "\n",
    "    w : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    attrs_name : list, required\n",
    "        Strings for attribute names to measure similarity\n",
    "        (cols of ``geopandas.GeoDataFrame``).\n",
    "\n",
    "    threshold_name : string, requied\n",
    "        The name of the spatial extensive attribute variable.\n",
    "\n",
    "    threshold : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    top_n : int\n",
    "        Max number of candidate regions for enclave assignment.\n",
    "\n",
    "    max_iterations_construction : int\n",
    "        Max number of iterations for construction phase.\n",
    "\n",
    "    max_iterations_SA: int\n",
    "        Max number of iterations for customized simulated annealing.\n",
    "\n",
    "    verbose : boolean\n",
    "        Set to ``True`` for reporting solution progress/debugging.\n",
    "        Default is ``False``.\n",
    "    policy : str\n",
    "        Defaults to ``single`` to attach infeasible components using a\n",
    "        single linkage between the area in the infeasible component\n",
    "        with the smallest nearest neighbor distance to an area in a\n",
    "        feasible component. ``multiple`` adds joins for each area\n",
    "        in an infeasible component and their nearest neighbor area in a\n",
    "        feasible component. ``keep`` attempts to solve without\n",
    "        modification (useful for debugging). ``drop`` removes areas in\n",
    "        infeasible components before solving.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    max_p : int\n",
    "        The number of regions.\n",
    "\n",
    "    labels : numpy.array\n",
    "        Region IDs for observations.\n",
    "\n",
    "    \"\"\"\n",
    "    gdf, w = modify_components(gdf, w, threshold_name, threshold, policy=policy)\n",
    "    attr = np.atleast_2d(gdf[attrs_name].values)\n",
    "    if attr.shape[0] == 1:\n",
    "        attr = attr.T\n",
    "    threshold_array = gdf[threshold_name].values\n",
    "    distance_matrix = squareform(pdist(attr, metric=\"cityblock\"))\n",
    "    n, k = attr.shape\n",
    "    arr = np.arange(n)\n",
    "    cStartTime = time.time()\n",
    "    max_p, rl_list = iterated_greedy_construction(\n",
    "        arr,\n",
    "        attr,\n",
    "        threshold_array,\n",
    "        distance_matrix,\n",
    "        w,\n",
    "        threshold,\n",
    "        top_n,\n",
    "        max_iterations_construction,\n",
    "    )\n",
    "    cEndTime = time.time()\n",
    "    cDuration  = cEndTime - cStartTime\n",
    "    if verbose:\n",
    "        print(\"max_p: \", max_p)\n",
    "        print(\"number of good partitions:\", len(rl_list))\n",
    "        print(\"Construction time: \", cDuration)\n",
    "\n",
    "    alpha = 0.998\n",
    "    tabuLength = 10\n",
    "    max_no_move = n\n",
    "    best_obj_value = np.inf\n",
    "    best_label = None\n",
    "    \n",
    "    for irl, rl in enumerate(rl_list):\n",
    "        label, regionList, regionSpatialAttr = rl\n",
    "        totalWithinRegionDistanceBeforeSA = calculate_within_region_distance(\n",
    "                regionList, distance_matrix\n",
    "            )\n",
    "        if verbose:\n",
    "            print(irl)\n",
    "        for _saiter in range(max_iterations_sa):\n",
    "            finalLabel, finalRegionList, finalRegionSpatialAttr = perform_sa(\n",
    "                label,\n",
    "                regionList,\n",
    "                regionSpatialAttr,\n",
    "                threshold_array,\n",
    "                w,\n",
    "                distance_matrix,\n",
    "                threshold,\n",
    "                alpha,\n",
    "                tabuLength,\n",
    "                max_no_move,\n",
    "                tarjan_flag = tarjan_flag\n",
    "            )\n",
    "            totalWithinRegionDistance = calculate_within_region_distance(\n",
    "                finalRegionList, distance_matrix\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"totalWithinRegionDistance before SA: \")\n",
    "                print(totalWithinRegionDistanceBeforeSA)\n",
    "                print(\"totalWithinRegionDistance after SA: \")\n",
    "                print(totalWithinRegionDistance)\n",
    "                print(\"Local search time: \", (time.time() - cEndTime))\n",
    "            if totalWithinRegionDistance < best_obj_value:\n",
    "                best_obj_value = totalWithinRegionDistance\n",
    "                best_label = finalLabel\n",
    "    if verbose:\n",
    "        print(\"best objective value:\")\n",
    "        print(best_obj_value)\n",
    "\n",
    "    return max_p, best_label\n",
    "\n",
    "\n",
    "def construction_phase(\n",
    "    arr,\n",
    "    attr,  # noqa ARG001\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    weight,\n",
    "    spatialThre,\n",
    "    random_assign_choice,\n",
    "    max_it=999,\n",
    "):\n",
    "    \"\"\"Construct feasible solutions for max-p-regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    arr : array, required\n",
    "        An array of index of area units.\n",
    "\n",
    "    attr : array, required\n",
    "        An array of the values of the attributes.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data.\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    random_assign_choice : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    max_it : int\n",
    "        Maximum number of iterations. Default is 999.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    real_values : list\n",
    "        ``realmaxpv``, ``realLabelsList``\n",
    "\n",
    "    \"\"\"\n",
    "    labels_list = []\n",
    "    pv_list = []\n",
    "    max_p = 0\n",
    "    maxp_labels = None\n",
    "    maxp_regionList = None\n",
    "    maxp_regionSpatialAttr = None\n",
    "\n",
    "    for _ in range(max_it):\n",
    "        labels = [0] * len(threshold_array)\n",
    "        C = 0\n",
    "        regionSpatialAttr = {}\n",
    "        enclave = []\n",
    "        regionList = {}\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        labeledID = []\n",
    "        #print(\"Iterateion \" , _)\n",
    "        failureCount = 0\n",
    "        \n",
    "        for arr_index in range(0, len(threshold_array)):\n",
    "            P = arr[arr_index]\n",
    "            if labels[P] != 0:\n",
    "                continue\n",
    "\n",
    "            NeighborPolys = deepcopy(weight.neighbors[P])\n",
    "\n",
    "            if len(NeighborPolys) == 0:\n",
    "                labels[P] = -1\n",
    "            else:\n",
    "                C += 1\n",
    "                labeledID, spatialAttrTotal = grow_cluster_for_poly(\n",
    "                    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "                )\n",
    "\n",
    "                if spatialAttrTotal < spatialThre:\n",
    "                    #print(\"Construction failed for \", P)\n",
    "                    failureCount += 1\n",
    "                    C -= 1\n",
    "                    enclave.extend(labeledID)\n",
    "                else:\n",
    "                    regionList[C] = labeledID\n",
    "                    regionSpatialAttr[C] = spatialAttrTotal\n",
    "        #print(\"Failure count for iteration \", _, \" is \" , failureCount)\n",
    "        num_regions = len(regionList)\n",
    "\n",
    "        for i, _l in enumerate(labels):\n",
    "            if _l == -1:\n",
    "                enclave.append(i)\n",
    "\n",
    "        if num_regions < max_p:\n",
    "            continue\n",
    "        else:\n",
    "            max_p = num_regions\n",
    "            maxp_labels, maxp_regionList, maxp_regionSpatialAttr = assign_enclave(\n",
    "                enclave,\n",
    "                labels,\n",
    "                regionList,\n",
    "                regionSpatialAttr,\n",
    "                threshold_array,\n",
    "                weight,\n",
    "                distance_matrix,\n",
    "                random_assign=random_assign_choice,\n",
    "            )\n",
    "            pv_list.append(max_p)\n",
    "            labels_list.append([maxp_labels, maxp_regionList, maxp_regionSpatialAttr])\n",
    "    realLabelsList = []\n",
    "    realmaxpv = max(pv_list)\n",
    "    for ipv, pv in enumerate(pv_list):\n",
    "        if pv == realmaxpv:\n",
    "            realLabelsList.append(labels_list[ipv])\n",
    "\n",
    "    real_values = [realmaxpv, realLabelsList]\n",
    "    return real_values\n",
    "\n",
    "\n",
    "def grow_cluster_for_poly(\n",
    "    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "):\n",
    "    \"\"\"Grow one region until threshold constraint is satisfied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    labels : list, required\n",
    "        A list of current region labels\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    P : int, required\n",
    "        The index of current area unit\n",
    "\n",
    "    NeighborPolys : list, required\n",
    "        The neighbors of current area unit\n",
    "\n",
    "    C : int, required\n",
    "        The index of current region\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    cluster_info : tuple\n",
    "        ``labeledID``, ``spatialAttrTotal``\n",
    "\n",
    "    \"\"\"\n",
    "    labels[P] = C\n",
    "    labeledID = [P]\n",
    "    spatialAttrTotal = threshold_array[P]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < len(NeighborPolys):\n",
    "        if spatialAttrTotal >= spatialThre:\n",
    "            break\n",
    "        Pn = NeighborPolys[i]\n",
    "\n",
    "        if labels[Pn] == 0:\n",
    "            labels[Pn] = C\n",
    "            labeledID.append(Pn)\n",
    "            spatialAttrTotal += threshold_array[Pn]\n",
    "            if spatialAttrTotal < spatialThre:\n",
    "                PnNeighborPolys = weight.neighbors[Pn]\n",
    "                for pnn in PnNeighborPolys:\n",
    "                    if pnn not in NeighborPolys:\n",
    "                        NeighborPolys.append(pnn)\n",
    "        i += 1\n",
    "\n",
    "    cluster_info = labeledID, spatialAttrTotal\n",
    "    return cluster_info\n",
    "\n",
    "\n",
    "def assign_enclave(\n",
    "    enclave,\n",
    "    labels,\n",
    "    regionList,\n",
    "    regionSpatialAttr,\n",
    "    threshold_array,\n",
    "    weight,\n",
    "    distance_matrix,\n",
    "    random_assign=1,\n",
    "):\n",
    "    \"\"\"Assign the enclaves to the regions identified in the region growth phase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    enclave : list, required\n",
    "        A list of enclaves.\n",
    "\n",
    "    labels : list, required\n",
    "        A list of region labels for area units.\n",
    "\n",
    "    regionList : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    regionSpatialAttr : dict, required\n",
    "        A dictionary with key as region ID and value as the total\n",
    "        spatial extensive attribute of the region.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    random_assign : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    region_info : list\n",
    "        Deep copies of ``labels``, ``regionList``, and ``regionSpatialAttr``\n",
    "\n",
    "    \"\"\"\n",
    "    enclave_index = 0\n",
    "    while len(enclave) > 0:\n",
    "        ec = enclave[enclave_index]\n",
    "        ecNeighbors = weight.neighbors[ec]\n",
    "        assignedRegion = 0\n",
    "        ecNeighborsList = []\n",
    "\n",
    "        for ecn in ecNeighbors:\n",
    "            if ecn in enclave:\n",
    "                continue\n",
    "            rm = np.array(regionList[labels[ecn]])\n",
    "            totalDistance = distance_matrix[ec, rm].sum()\n",
    "            ecNeighborsList.append((ecn, totalDistance))\n",
    "        ecNeighborsList = sorted(ecNeighborsList, key=lambda tup: tup[1])\n",
    "        top_num = min([len(ecNeighborsList), random_assign])\n",
    "        if top_num > 0:\n",
    "            ecn_index = np.random.randint(top_num)\n",
    "            assignedRegion = labels[ecNeighborsList[ecn_index][0]]\n",
    "\n",
    "        if assignedRegion == 0:\n",
    "            enclave_index += 1\n",
    "        else:\n",
    "            labels[ec] = assignedRegion\n",
    "            regionList[assignedRegion].append(ec)\n",
    "            regionSpatialAttr[assignedRegion] += threshold_array[ec]\n",
    "            del enclave[enclave_index]\n",
    "            enclave_index = 0\n",
    "\n",
    "    region_info = [deepcopy(labels), deepcopy(regionList), deepcopy(regionSpatialAttr)]\n",
    "    return region_info\n",
    "\n",
    "\n",
    "def calculate_within_region_distance(regionList, distance_matrix):\n",
    "    \"\"\"Calculate total wthin-region distance/dissimilarity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    regionList : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    totalWithinRegionDistance : {int, float}\n",
    "        the total within-region distance\n",
    "\n",
    "    \"\"\"\n",
    "    totalWithinRegionDistance = 0\n",
    "    for _k, v in regionList.items():\n",
    "        nv = np.array(v)\n",
    "        regionDistance = distance_matrix[nv, :][:, nv].sum() / 2\n",
    "        totalWithinRegionDistance += regionDistance\n",
    "\n",
    "    return totalWithinRegionDistance\n",
    "\n",
    "\n",
    "\n",
    "def check_move(\n",
    "    poa,\n",
    "    labels,\n",
    "    regionLists,\n",
    "    threshold_array,  # noqa ARG001\n",
    "    weight,\n",
    "    distance_matrix,\n",
    "    threshold,  # noqa ARG001\n",
    "):\n",
    "    \"\"\"Calculate the dissimilarity increase/decrease from one potential move.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    poa : int, required\n",
    "        The index of current area unit that can potentially move\n",
    "\n",
    "    labels : list, required\n",
    "        A list of current region labels\n",
    "\n",
    "    regionLists : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    threshold : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    move_info : list\n",
    "        ``lostDistance``, ``minAddedDistance``, and ``potentialMove``.\n",
    "\n",
    "    \"\"\"\n",
    "    poaNeighbor = weight.neighbors[poa]\n",
    "    donorRegion = labels[poa]\n",
    "\n",
    "    rm = np.array(regionLists[donorRegion])\n",
    "    lostDistance = distance_matrix[poa, rm].sum()\n",
    "    potentialMove = None\n",
    "\n",
    "    minAddedDistance = np.Inf\n",
    "    for poan in poaNeighbor:\n",
    "        recipientRegion = labels[poan]\n",
    "        if donorRegion != recipientRegion:\n",
    "            rm = np.array(regionLists[recipientRegion])\n",
    "            addedDistance = distance_matrix[poa, rm].sum()\n",
    "\n",
    "            if addedDistance < minAddedDistance:\n",
    "                minAddedDistance = addedDistance\n",
    "                potentialMove = (poa, donorRegion, recipientRegion)\n",
    "\n",
    "    move_info = [lostDistance, minAddedDistance, potentialMove]\n",
    "    return move_info\n",
    "\n",
    "\n",
    "def perform_sa(\n",
    "    initLabels,\n",
    "    initRegionList,\n",
    "    initRegionSpatialAttr,\n",
    "    threshold_array,\n",
    "    weight,\n",
    "    distance_matrix,\n",
    "    threshold,\n",
    "    alpha,\n",
    "    tabuLength,\n",
    "    max_no_move,\n",
    "    tarjan_flag = True\n",
    "):\n",
    "    \"\"\"Perform the tabu list integrated simulated annealing algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    initLabels : list, required\n",
    "        A list of initial region labels before SA\n",
    "\n",
    "    initRegionList : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region before SA.\n",
    "\n",
    "    initRegionSpatialAttr : dict, required\n",
    "        A dictionary with key as region ID and value as the total\n",
    "        spatial extensive attribute of the region before SA.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data.\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    threshold : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    alpha : float between 0 and 1, required\n",
    "        Temperature cooling rate\n",
    "\n",
    "    tabuLength : int, required\n",
    "        Max length of a tabuList\n",
    "\n",
    "    max_no_move : int, required\n",
    "        Max number of none improving movements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    sa_res : list\n",
    "        The results from simulated annealing including ``labels``,\n",
    "        ``regionLists``, and ``regionSpatialAttrs``.\n",
    "\n",
    "    \"\"\"\n",
    "    t = 1\n",
    "    ni_move_ct = 0\n",
    "    make_move_flag = False\n",
    "    tabuList = []\n",
    "    potentialAreas = []\n",
    "\n",
    "    labels = deepcopy(initLabels)\n",
    "    regionLists = deepcopy(initRegionList)\n",
    "    regionSpatialAttrs = deepcopy(initRegionSpatialAttr)\n",
    "\n",
    "    while ni_move_ct <= max_no_move:\n",
    "        if len(potentialAreas) == 0:\n",
    "            potentialAreas = pick_move_area(\n",
    "                labels,\n",
    "                regionLists,\n",
    "                regionSpatialAttrs,\n",
    "                threshold_array,\n",
    "                weight,\n",
    "                distance_matrix,\n",
    "                threshold,\n",
    "                tarjan=tarjan_flag\n",
    "            )\n",
    "\n",
    "        if len(potentialAreas) == 0:\n",
    "            break\n",
    "        poa = potentialAreas[np.random.randint(len(potentialAreas))]\n",
    "        lostDistance, minAddedDistance, potentialMove = check_move(\n",
    "            poa,\n",
    "            labels,\n",
    "            regionLists,\n",
    "            threshold_array,\n",
    "            weight,\n",
    "            distance_matrix,\n",
    "            threshold,\n",
    "        )\n",
    "\n",
    "        if potentialMove is None:\n",
    "            potentialAreas.remove(poa)\n",
    "            continue\n",
    "\n",
    "        diff = lostDistance - minAddedDistance\n",
    "        donorRegion = potentialMove[1]\n",
    "        recipientRegion = potentialMove[2]\n",
    "\n",
    "        if diff > 0:\n",
    "            make_move_flag = True\n",
    "            if (poa, recipientRegion, donorRegion) not in tabuList:\n",
    "                if len(tabuList) == tabuLength:\n",
    "                    tabuList.pop(0)\n",
    "                tabuList.append((poa, donorRegion, recipientRegion))\n",
    "\n",
    "            ni_move_ct = 0\n",
    "        else:\n",
    "            ni_move_ct += 1\n",
    "            prob = np.exp(diff / t)\n",
    "            if prob > np.random.random() and potentialMove not in tabuList:\n",
    "                make_move_flag = True\n",
    "            else:\n",
    "                make_move_flag = False\n",
    "\n",
    "        potentialAreas.remove(poa)\n",
    "        if make_move_flag:\n",
    "            labels[poa] = recipientRegion\n",
    "            regionLists[donorRegion].remove(poa)\n",
    "            regionLists[recipientRegion].append(poa)\n",
    "            regionSpatialAttrs[donorRegion] -= threshold_array[poa]\n",
    "            regionSpatialAttrs[recipientRegion] += threshold_array[poa]\n",
    "\n",
    "            impactedAreas = []\n",
    "            for pa in potentialAreas:\n",
    "                if labels[pa] == recipientRegion or labels[pa] == donorRegion:\n",
    "                    impactedAreas.append(pa)\n",
    "            for pa in impactedAreas:\n",
    "                potentialAreas.remove(pa)\n",
    "\n",
    "        t = t * alpha\n",
    "    return [labels, regionLists, regionSpatialAttrs]\n",
    "\n",
    "\n",
    "\n",
    "class MaxPHeuristic_IG(BaseSpOptHeuristicSolver):\n",
    "    \"\"\"The max-p-regions involves the aggregation of n areas into an\n",
    "    unknown maximum number of homogeneous regions, while ensuring that\n",
    "    each region is contiguious and satisfies a minimum threshold value\n",
    "    imposed on a predefined spatially extensive attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    gdf : geopandas.GeoDataFrame, required\n",
    "        Geodataframe containing original data.\n",
    "\n",
    "    w : libpysal.weights.W, required\n",
    "        Weights object created from given data.\n",
    "\n",
    "    attrs_name : list, required\n",
    "        Strings for attribute names (cols of ``geopandas.GeoDataFrame``).\n",
    "\n",
    "    threshold_name : string, required\n",
    "        The name of the spatial extensive attribute variable.\n",
    "\n",
    "    threshold : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    top_n : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    max_iterations_construction : int\n",
    "        Max number of iterations for construction phase.\n",
    "\n",
    "    max_iterations_SA : int\n",
    "        Max number of iterations for customized simulated annealing.\n",
    "\n",
    "    verbose : boolean\n",
    "        Set to ``True`` for reporting solution progress/debugging.\n",
    "        Default is ``False``.\n",
    "\n",
    "    policy : str\n",
    "        Defaults to ``'single'`` to attach infeasible components using a\n",
    "        single linkage between the area in the infeasible component\n",
    "        with the smallest nearest neighbor distance to an area in a\n",
    "        feasible component. ``'multiple'`` adds joins for each area\n",
    "        in an infeasible component and their nearest neighbor area in a\n",
    "        feasible component. ``'keep'`` attempts to solve without\n",
    "        modification (useful for debugging). ``'drop'`` removes areas in\n",
    "        infeasible components before solving.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    max_p : int\n",
    "        The number of regions.\n",
    "    labels_ : numpy.array\n",
    "        Region IDs for observations.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> import numpy\n",
    "    >>> import libpysal\n",
    "    >>> import geopandas as gpd\n",
    "    >>> from spopt.region.maxp import MaxPHeuristic\n",
    "\n",
    "    Read the data.\n",
    "\n",
    "    >>> pth = libpysal.examples.get_path(\"mexicojoin.shp\")\n",
    "    >>> mexico = gpd.read_file(pth)\n",
    "    >>> mexico[\"count\"] = 1\n",
    "\n",
    "    Create the weight.\n",
    "\n",
    "    >>> w = libpysal.weights.Queen.from_dataframe(mexico)\n",
    "\n",
    "    Define the columns of ``geopandas.GeoDataFrame`` to be spatially\n",
    "    extensive attribute.\n",
    "\n",
    "    >>> attrs_name = [f\"PCGDP{year}\" for year in range(1950, 2010, 10)]\n",
    "\n",
    "    Define the spatial extensive attribute variable and the threshold value.\n",
    "\n",
    "    >>> threshold_name = \"count\"\n",
    "    >>> threshold = 4\n",
    "\n",
    "    Run the max-p-regions algorithm.\n",
    "\n",
    "    >>> model = MaxPHeuristic(mexico, w, attrs_name, threshold_name, threshold)\n",
    "    >>> model.solve()\n",
    "\n",
    "    Get the number of regions and region IDs for unit areas.\n",
    "\n",
    "    >>> model.p\n",
    "    >>> model.labels_\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        gdf,\n",
    "        w,\n",
    "        attrs_name,\n",
    "        threshold_name,\n",
    "        threshold,\n",
    "        top_n=2,\n",
    "        max_iterations_construction=99,\n",
    "        max_iterations_sa=ITERSA,\n",
    "        verbose=False,\n",
    "        policy=\"single\",\n",
    "        initial_it = 1,\n",
    "        deconstruct_it = 1000,\n",
    "        reconst_it = 99,\n",
    "        disturbance_intensity = 0.01,\n",
    "        max_it=1,\n",
    "        tarjan_flag = True\n",
    "    ):\n",
    "        self.gdf = gdf\n",
    "        self.w = w\n",
    "        self.attrs_name = attrs_name\n",
    "        self.threshold_name = threshold_name\n",
    "        self.threshold = threshold\n",
    "        self.top_n = top_n\n",
    "        self.max_iterations_construction = max_iterations_construction\n",
    "        self.max_iterations_sa = max_iterations_sa\n",
    "        self.verbose = verbose\n",
    "        self.policy = policy\n",
    "        self.initial_it = initial_it\n",
    "        self.deconstruct_it = deconstruct_it\n",
    "        self.reconst_it = reconst_it\n",
    "        self.disturbance_intensity = disturbance_intensity\n",
    "        self.max_it = max_it\n",
    "        self.tarjan_flag = tarjan_flag\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Solve a max-p-regions problem and get back the results.\"\"\"\n",
    "        max_p, label = iterated_maxp(\n",
    "            self.gdf,\n",
    "            self.w,\n",
    "            self.attrs_name,\n",
    "            self.threshold_name,\n",
    "            self.threshold,\n",
    "            self.top_n,\n",
    "            self.max_iterations_construction,\n",
    "            self.max_iterations_sa,\n",
    "            verbose=self.verbose,\n",
    "            policy=self.policy,\n",
    "            initial_it=self.initial_it,\n",
    "            deconstruct_it=self.deconstruct_it,\n",
    "            reconst_it=self.reconst_it,\n",
    "            disturbance_intensity=self.disturbance_intensity,\n",
    "            max_it=self.max_it,\n",
    "            tarjan_flag = self.tarjan_flag\n",
    "        )\n",
    "        self.labels_ = label\n",
    "        self.p = max_p\n",
    "\n",
    "def dfs(\n",
    "    area_index,\n",
    "    region_graph,\n",
    "    visited,\n",
    "    discovery_time,\n",
    "    low,\n",
    "    parent,\n",
    "    time,\n",
    "    articulation_points\n",
    "):\n",
    "    \"\"\"The depth-first search(DFS) for the Tarjan algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    area_index : int, required\n",
    "        The index of area for starting the DFS\n",
    "\n",
    "    region_graph : dict, required\n",
    "        A dictionary with key as area ID and value as a list of \n",
    "        neighbor areas.\n",
    "\n",
    "    visited : array, required\n",
    "        An array that indicating whether each area has been visited\n",
    "\n",
    "    discovery_time : array, required\n",
    "        An array of the discovery time of the areas during the BFS traversal.\n",
    "\n",
    "    low :array, required\n",
    "        An array of the topmost reachable ancestor for each area in the DFS\n",
    "\n",
    "    parent : array, required\n",
    "        The array of the parent of each area in the DFS traversal\n",
    "    time : int\n",
    "        The time stamp of the DFS traversal\n",
    "\n",
    "    articulation_points : list\n",
    "        a list of atriculation area units which will cause the number of connected components to increase once removed.\n",
    "\n",
    "    \"\"\"\n",
    "    visited[area_index] = True\n",
    "    discovery_time[area_index] = time\n",
    "    low[area_index] = time\n",
    "    children = 0\n",
    "    for neighbor_index in region_graph[area_index]:\n",
    "        if not visited[neighbor_index]:\n",
    "            parent[neighbor_index] = area_index\n",
    "            children += 1\n",
    "            dfs(neighbor_index, region_graph, visited, discovery_time, low, parent, time + 1, articulation_points)\n",
    "            low[area_index] = min(low[area_index], low[neighbor_index])\n",
    "\n",
    "            if parent[area_index] == -1 and children > 1:\n",
    "                articulation_points.add(area_index)\n",
    "                #print(\"Area\" , area_index, \" added as root\")\n",
    "            elif parent[area_index] != -1 and low[neighbor_index] >= discovery_time[area_index]:\n",
    "                articulation_points.add(area_index)\n",
    "                #print(\"Area\" , area_index, \" added as articluation \", parent[area_index])\n",
    "        elif neighbor_index != parent[area_index]:\n",
    "            low[area_index] = min(low[area_index], discovery_time[neighbor_index])\n",
    "def get_articulation_points(\n",
    "    areas_in_region,\n",
    "    weight_sparse\n",
    "): \n",
    "    \"\"\"Get the articulation points out of a set of areas in a region.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    areas_in_region : array, required\n",
    "        The id of the areas in the region\n",
    "\n",
    "    weight_sparse : libpysal.weights.WSP, required\n",
    "        The sparse weights object created from given data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    articulation_points : list\n",
    "        A list of artulation points\n",
    "\n",
    "    \"\"\"\n",
    "    edges_with_index = weight_sparse[areas_in_region, :][:, areas_in_region]\n",
    "    region_graph = defaultdict(list)\n",
    "    cx = coo_matrix(edges_with_index)  \n",
    "    #print(cx)\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "        region_graph[i].append(j)\n",
    "    \n",
    "    visited = False * areas_in_region\n",
    "    #print(visited)\n",
    "    discovery_time = [-1] * areas_in_region.size\n",
    "    low = [-1] * areas_in_region.size\n",
    "    parent = [-1] * areas_in_region.size\n",
    "    #print(parent)\n",
    "    time = 0\n",
    "    articulation_points = set()\n",
    "    for area_index in range(areas_in_region.size):\n",
    "        if not visited[area_index]:\n",
    "            dfs(area_index, region_graph, visited, discovery_time, low, parent, time, articulation_points)\n",
    "    return list(articulation_points)\n",
    "\n",
    "def pick_move_area(\n",
    "    labels,  # noqa ARG001\n",
    "    regionLists,\n",
    "    regionSpatialAttrs,\n",
    "    threshold_array,\n",
    "    weight,\n",
    "    distance_matrix,  # noqa ARG001\n",
    "    threshold,\n",
    "    tarjan = True\n",
    "):\n",
    "    \"\"\"Pick a spatial unit that can move from one region to another.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    labels : list, required\n",
    "        A list of current region labels\n",
    "\n",
    "    regionLists : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    regionSpatialAttrs : dict, required\n",
    "        A dictionary with key as region ID and value as the total\n",
    "        spatial extensive attribute of the region.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight :libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    threshold : {int, float}, required\n",
    "        The threshold value.\n",
    "    tarjan : {boolean}\n",
    "        Set to 'True' by default to use the Tarjan algorithm for picking \n",
    "        the potential areas. 1-CC method is used for each area if set to 'False'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    potentialAreas : list\n",
    "        a list of area units that can move without violating\n",
    "        contiguity and threshold constraints\n",
    "\n",
    "    \"\"\"\n",
    "    potentialAreas = []\n",
    "    for k, v in regionSpatialAttrs.items():\n",
    "        rla = np.array(regionLists[k])\n",
    "        rasa = threshold_array[rla]\n",
    "        lostSA = v - rasa\n",
    "        pas_indices = np.where(lostSA > threshold)[0]\n",
    "        if pas_indices.size > 0:\n",
    "            if tarjan:\n",
    "                ap = get_articulation_points(rla, weight.sparse)\n",
    "                potentialAreas.extend(list(rla[list(np.setdiff1d(pas_indices, ap))]))\n",
    "            else:\n",
    "                tmp_potentialArea = []\n",
    "                for pasi in pas_indices:\n",
    "                    leftAreas = np.delete(rla, pasi)\n",
    "                    ws = weight.sparse\n",
    "                    cc = connected_components(ws[leftAreas, :][:, leftAreas])\n",
    "                    if cc[0] == 1:\n",
    "                        tmp_potentialArea.append(rla[pasi])\n",
    "                potentialAreas.extend(tmp_potentialArea)\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            continue\n",
    "    return potentialAreas\n",
    "\n",
    "def partial_construction_phase(\n",
    "    arr,\n",
    "    attr,  # noqa ARG001\n",
    "    deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    weight,\n",
    "    spatialThre,\n",
    "    random_assign_choice,\n",
    "    max_it=99,\n",
    "):\n",
    "    \"\"\"Construct feasible solutions for max-p-regions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    arr : array, required\n",
    "        An array of index of area units.\n",
    "\n",
    "    attr : array, required\n",
    "        An array of the values of the attributes.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data.\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    random_assign_choice : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    max_it : int\n",
    "        Maximum number of iterations. Default is 999.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    real_values : list\n",
    "        ``realmaxpv``, ``realLabelsList``\n",
    "\n",
    "    \"\"\"\n",
    "    labels_list = []\n",
    "    pv_list = []\n",
    "    max_p = 0\n",
    "    maxp_labels = None\n",
    "    maxp_regionList = None\n",
    "    maxp_regionSpatialAttr = None\n",
    "\n",
    "    for _ in range(max_it):\n",
    "        labels = [-2] * len(threshold_array)\n",
    "        for i in deconstruct_areas:\n",
    "            labels[i] = 0\n",
    "        C = 0\n",
    "        regionSpatialAttr = {}\n",
    "        enclave = []\n",
    "        regionList = {}\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        labeledID = []\n",
    "        #print(\"Iterateion \" , _)\n",
    "        failureCount = 0\n",
    "        \n",
    "        for arr_index in range(0, len(threshold_array)):\n",
    "            P = arr[arr_index]\n",
    "            if labels[P] != 0:\n",
    "                continue\n",
    "\n",
    "            NeighborPolys = deepcopy(weight.neighbors[P])\n",
    "\n",
    "            if len(NeighborPolys) == 0:\n",
    "                labels[P] = -1\n",
    "            else:\n",
    "                C += 1\n",
    "                labeledID, spatialAttrTotal = partial_grow_cluster_for_poly(\n",
    "                    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "                )\n",
    "                \n",
    "                if spatialAttrTotal < spatialThre:\n",
    "                    #print(\"Construction failed for \", P)\n",
    "                    failureCount += 1\n",
    "                    C -= 1\n",
    "                    enclave.extend(labeledID)\n",
    "                else:\n",
    "                    regionList[C] = labeledID\n",
    "                    regionSpatialAttr[C] = spatialAttrTotal\n",
    "        #print(\"Failure count for iteration \", _, \" is \" , failureCount)\n",
    "        num_regions = len(regionList)\n",
    "\n",
    "        for i, _l in enumerate(labels):\n",
    "            if _l == -1:\n",
    "                enclave.append(i)\n",
    "\n",
    "        if num_regions < max_p:\n",
    "            continue\n",
    "        else:\n",
    "            max_p = num_regions\n",
    "            maxp_labels, maxp_regionList, maxp_regionSpatialAttr = assign_enclave(\n",
    "                enclave,\n",
    "                labels,\n",
    "                regionList,\n",
    "                regionSpatialAttr,\n",
    "                threshold_array,\n",
    "                weight,\n",
    "                distance_matrix,\n",
    "                random_assign=random_assign_choice,\n",
    "            )\n",
    "            pv_list.append(max_p)\n",
    "            labels_list.append([maxp_labels, maxp_regionList, maxp_regionSpatialAttr])\n",
    "    realLabelsList = []\n",
    "    realmaxpv = max(pv_list)\n",
    "    for ipv, pv in enumerate(pv_list):\n",
    "        if pv == realmaxpv:\n",
    "            realLabelsList.append(labels_list[ipv])\n",
    "\n",
    "    real_values = [realmaxpv, realLabelsList]\n",
    "    return real_values\n",
    "\n",
    "def partial_grow_cluster_for_poly(\n",
    "    labels, threshold_array, P, NeighborPolys, C, weight, spatialThre\n",
    "):\n",
    "    \"\"\"Grow one region until threshold constraint is satisfied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    labels : list, required\n",
    "        A list of current region labels\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    P : int, required\n",
    "        The index of current area unit\n",
    "\n",
    "    NeighborPolys : list, required\n",
    "        The neighbors of current area unit\n",
    "\n",
    "    C : int, required\n",
    "        The index of current region\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    spatialThre : {int, float}, required\n",
    "        The threshold value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    cluster_info : tuple\n",
    "        ``labeledID``, ``spatialAttrTotal``\n",
    "\n",
    "    \"\"\"\n",
    "    labels[P] = C\n",
    "    labeledID = [P]\n",
    "    spatialAttrTotal = threshold_array[P]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < len(NeighborPolys):\n",
    "        if spatialAttrTotal >= spatialThre:\n",
    "            break\n",
    "        Pn = NeighborPolys[i]\n",
    "\n",
    "        if labels[Pn] == 0:\n",
    "            labels[Pn] = C\n",
    "            labeledID.append(Pn)\n",
    "            spatialAttrTotal += threshold_array[Pn]\n",
    "            if spatialAttrTotal < spatialThre:\n",
    "                PnNeighborPolys = weight.neighbors[Pn]\n",
    "                for pnn in PnNeighborPolys:\n",
    "                    if pnn not in NeighborPolys:\n",
    "                        NeighborPolys.append(pnn)\n",
    "        i += 1\n",
    "\n",
    "    cluster_info = labeledID, spatialAttrTotal\n",
    "    return cluster_info\n",
    "\n",
    "\n",
    "def assign_enclave(\n",
    "    enclave,\n",
    "    labels,\n",
    "    regionList,\n",
    "    regionSpatialAttr,\n",
    "    threshold_array,\n",
    "    weight,\n",
    "    distance_matrix,\n",
    "    random_assign=1,\n",
    "):\n",
    "    \"\"\"Assign the enclaves to the regions identified in the region growth phase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    enclave : list, required\n",
    "        A list of enclaves.\n",
    "\n",
    "    labels : list, required\n",
    "        A list of region labels for area units.\n",
    "\n",
    "    regionList : dict, required\n",
    "        A dictionary with key as region ID and value as a list of area\n",
    "        units assigned to the region.\n",
    "\n",
    "    regionSpatialAttr : dict, required\n",
    "        A dictionary with key as region ID and value as the total\n",
    "        spatial extensive attribute of the region.\n",
    "\n",
    "    threshold_array : array, required\n",
    "        An array of the values of the spatial extensive attribute.\n",
    "\n",
    "    weight : libpysal.weights.W, required\n",
    "        Weights object created from given data\n",
    "\n",
    "    distance_matrix : array, required\n",
    "        A square-form distance matrix for the attributes.\n",
    "\n",
    "    random_assign : int, required\n",
    "        The number of top candidate regions to consider for enclave assignment.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    region_info : list\n",
    "        Deep copies of ``labels``, ``regionList``, and ``regionSpatialAttr``\n",
    "\n",
    "    \"\"\"\n",
    "    enclave_index = 0\n",
    "    while len(enclave) > 0:\n",
    "        #print(\"enclave index: \", enclave_index)\n",
    "        #print(\"enclave list length: \", len(enclave))\n",
    "        ec = enclave[enclave_index]\n",
    "        ecNeighbors = weight.neighbors[ec]\n",
    "        assignedRegion = 0\n",
    "        ecNeighborsList = []\n",
    "\n",
    "        for ecn in ecNeighbors:\n",
    "            if ecn in enclave or labels[ecn] == -2:\n",
    "                continue\n",
    "            rm = np.array(regionList[labels[ecn]])\n",
    "            totalDistance = distance_matrix[ec, rm].sum()\n",
    "            ecNeighborsList.append((ecn, totalDistance))\n",
    "        ecNeighborsList = sorted(ecNeighborsList, key=lambda tup: tup[1])\n",
    "        top_num = min([len(ecNeighborsList), random_assign])\n",
    "        if top_num > 0:\n",
    "            ecn_index = np.random.randint(top_num)\n",
    "            assignedRegion = labels[ecNeighborsList[ecn_index][0]]\n",
    "\n",
    "        if assignedRegion == 0:\n",
    "            enclave_index += 1\n",
    "        else:\n",
    "            labels[ec] = assignedRegion\n",
    "            regionList[assignedRegion].append(ec)\n",
    "            regionSpatialAttr[assignedRegion] += threshold_array[ec]\n",
    "            del enclave[enclave_index]\n",
    "            enclave_index = 0\n",
    "\n",
    "    region_info = [deepcopy(labels), deepcopy(regionList), deepcopy(regionSpatialAttr)]\n",
    "    return region_info\n",
    "\n",
    "def checkResult(\n",
    "        labels,\n",
    "        regionAreaDic,\n",
    "        regionAttrDic,\n",
    "        threshold_array\n",
    "):\n",
    "    status = 0\n",
    "    realAttrDic = dict()\n",
    "    for regionId in regionAreaDic:\n",
    "        regionAttrTotal = 0\n",
    "        for area in regionAreaDic[regionId]:\n",
    "            regionAttrTotal += threshold_array[area]\n",
    "            if labels[area] != regionId:\n",
    "                print(\"Area \", area, \" is labled in region (\", labels[area], \") but in the list of (\", regionId, \")\")\n",
    "                status = -1\n",
    "        if regionAttrTotal != regionAttrDic[regionId]:\n",
    "                print(\"Region (\", regionId, \") attribute does not match\")\n",
    "                status = -2\n",
    "    print(\"Checking finished with status: \", status)\n",
    "\n",
    "def get_one_hop_neighbor_regions(\n",
    "    regionIds,\n",
    "    labels,\n",
    "    weight\n",
    "):\n",
    "    one_hop_neighbor_set = set()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in regionIds:\n",
    "            neighbor_list = [labels[j] for j in weight.neighbors[i]]\n",
    "            one_hop_neighbor_set.update(neighbor_list)\n",
    "    return one_hop_neighbor_set\n",
    "def get_deconstruct_areas(\n",
    "    regionIds,\n",
    "    labels\n",
    "):\n",
    "    deconstruct_areas = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in regionIds:\n",
    "            deconstruct_areas.append(i)\n",
    "    return deconstruct_areas\n",
    "def iterated_greedy_construction(\n",
    "    arr,\n",
    "    attr,  # noqa ARG001\n",
    "    #deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    w,\n",
    "    sum_low,\n",
    "    top_n,\n",
    "    initial_it = 1,\n",
    "    deconstruct_it = 1000,\n",
    "    reconst_it = 99,\n",
    "    disturbance_intensity = 0.05,\n",
    "    max_it=1,\n",
    "    max_no_improvement_count = 50,\n",
    "    verbose = False\n",
    "):\n",
    "    cStartTime = time.time()\n",
    "    c_max_p, c_rl_list = construction_phase(\n",
    "        arr,\n",
    "        attr,  # noqa ARG001\n",
    "        #deconstruct_areas,\n",
    "        threshold_array,\n",
    "        distance_matrix,\n",
    "        w,\n",
    "        sum_low,\n",
    "        top_n,\n",
    "        max_it=initial_it,\n",
    "    )\n",
    "    cEndTime = time.time()\n",
    "    if verbose:\n",
    "        print(\"Start with p: \", c_max_p)\n",
    "        print(\"Construction time: \", cEndTime - cStartTime)\n",
    "    no_improvement_count = 0\n",
    "    for i in range(deconstruct_it):\n",
    "        no_improvement_count += 1\n",
    "        if(no_improvement_count > max_no_improvement_count):\n",
    "            break\n",
    "        \"\"\"center_region = []\n",
    "        for i in range(disturbance_intensity):\n",
    "            center_region.append(numpy.random.randint(1, c_max_p))\n",
    "        one_hop_regions = get_one_hop_neighbor_regions(center_region, c_rl_list[0][0], w)\n",
    "        deconstruct_areas = get_deconstruct_areas(one_hop_regions, c_rl_list[0][0])\"\"\"\n",
    "        #deconstruct_areas = []\n",
    "        deconstruct_areas_set = set()\n",
    "        deconstructed_region_set = set()\n",
    "        while(len(deconstruct_areas_set) < attr.size * disturbance_intensity):\n",
    "            #print(i, \" \", len(deconstruct_areas_set), \" \", attr.size * disturbance_intensity)\n",
    "            center_region = []\n",
    "            center_region.append(numpy.random.randint(1, c_max_p))\n",
    "            one_hop_regions = get_one_hop_neighbor_regions(center_region, c_rl_list[0][0], w)\n",
    "            deconstructed_region_set.update(one_hop_regions)\n",
    "            deconstruct_areas_set.update(get_deconstruct_areas(one_hop_regions, c_rl_list[0][0]))\n",
    "        deconstruct_areas = list(deconstruct_areas_set)\n",
    "        \n",
    "        deconstruct_threshold_values = [threshold_array[i] for i in deconstruct_areas]\n",
    "        #print(\"Reconstruct \", deconstruct_areas)\n",
    "        #print(\"Threshold attrs \", deconstruct_threshold_values)\n",
    "        #print(\"Threshold \", sum_low)\n",
    "        #print(\"Total attr deconstructed \", sum(deconstruct_threshold_values))\n",
    "\n",
    "        max_p, rl_list = partial_construction_phase(\n",
    "            arr,\n",
    "            attr,  # noqa ARG001\n",
    "            deconstruct_areas,\n",
    "            threshold_array,\n",
    "            distance_matrix,\n",
    "            w,\n",
    "            sum_low,\n",
    "            top_n,\n",
    "            max_it=9,\n",
    "        )\n",
    "        #print(\"Reconstructed p: \", max_p)\n",
    "        #print(len(rl_list[0][1]))\n",
    "        #print(\"Better? \", max_p > len(one_hop_regions))\n",
    "        dec_region_value = 0\n",
    "        dec_area_value = 0\n",
    "        #print(c_rl_list[0][2])\n",
    "        #checkResult(c_rl_list[0][0], c_rl_list[0][1], c_rl_list[0][2], threshold_array)\n",
    "        #print(c_rl_list[0][2])\n",
    "        for r in deconstructed_region_set:\n",
    "            dec_region_value += c_rl_list[0][2][r]\n",
    "        for a in deconstruct_areas:\n",
    "            dec_area_value += threshold_array[a]\n",
    "        #print(\"Valid?\", dec_region_value, \" ? \", dec_area_value , \" ? \",sum(rl_list[0][2].values()))\n",
    "        #print(rl_list[0][1])\n",
    "        #print(c_max_p)\n",
    "        '''print(c_rl_list[0][2])'''\n",
    "        if(max_p > len(deconstructed_region_set)):  #There is improvement in termes of number of regions\n",
    "            p_difference = max_p - len(deconstructed_region_set)\n",
    "            no_improvement_count = 0\n",
    "            for i in range(1, len(deconstructed_region_set) + 1):\n",
    "                #print(i)\n",
    "                #print(list(one_hop_regions)[i-1])\n",
    "                #print(i)\n",
    "                #print(rl_list[0][1][i])\n",
    "                for area in rl_list[0][1][i]:\n",
    "                    c_rl_list[0][0][area] = list(deconstructed_region_set)[i-1]\n",
    "                c_rl_list[0][1][list(deconstructed_region_set)[i-1]] = rl_list[0][1][i]\n",
    "                c_rl_list[0][2][list(deconstructed_region_set)[i-1]] = rl_list[0][2][i]\n",
    "            for i in range(len(deconstructed_region_set) + 1, max_p + 1):\n",
    "                new_regionId = c_max_p + i - len(deconstructed_region_set)\n",
    "                #print(\"New region: \", new_regionId)\n",
    "                #print(rl_list[0][1][i + len(one_hop_regions)])\n",
    "                for area in rl_list[0][1][i]:\n",
    "                    c_rl_list[0][0][area] = new_regionId\n",
    "                c_rl_list[0][1][new_regionId] = rl_list[0][1][i]\n",
    "                c_rl_list[0][2][new_regionId] = rl_list[0][2][i]\n",
    "            c_max_p += p_difference\n",
    "    rEndTime = time.time()\n",
    "    if verbose:\n",
    "        print(\"Ends with: \", c_max_p)\n",
    "        print(\"Reconstruction time: \", rEndTime - cEndTime)\n",
    "    return c_max_p, c_rl_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409   85.65780091285706\n",
      "408   50.58360314369202\n",
      "408   47.54253649711609\n",
      "404   77.46319317817688\n",
      "410   50.4761266708374\n",
      "403   46.474801778793335\n",
      "408   167.12023258209229\n",
      "405   43.640082597732544\n",
      "410   47.81810545921326\n"
     ]
    }
   ],
   "source": [
    "top_n = 2\n",
    "sum_attr = 'pop2010'\n",
    "sum_low = 20000.0\n",
    "dis_attr = 'households'\n",
    "#RANDOM_SEED = 123456\n",
    "#numpy.random.seed(RANDOM_SEED)\n",
    "for di in range(1, 10):\n",
    "    start_time = time.time()\n",
    "    model = MaxPHeuristic_IG(lacity, w, dis_attr, sum_attr, sum_low, top_n, verbose = False, initial_it = 1,\n",
    "        deconstruct_it = 1000,\n",
    "        reconst_it = 99,\n",
    "        disturbance_intensity = di/100,\n",
    "        max_it=1, tarjan_flag = True)\n",
    "    model.solve()\n",
    "    print(model.p, \" \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with p:  374\n",
      "Construction time:  0.07079863548278809\n",
      "Ends with:  408\n",
      "Reconstruction time:  16.710644006729126\n",
      "(408, [[[131, 25, 305, 176, 20, 190, 26, 142, 113, 113, 275, 275, 104, 249, 38, 141, 141, 172, 172, 172, 285, 308, 35, 160, 65, 345, 33, 255, 345, 143, 153, 264, 153, 283, 324, 324, 283, 283, 74, 256, 172, 285, 302, 236, 118, 118, 118, 10, 173, 7, 7, 7, 73, 22, 22, 22, 384, 340, 10, 7, 10, 22, 350, 78, 164, 130, 218, 218, 324, 111, 111, 228, 369, 142, 388, 102, 76, 45, 76, 76, 150, 150, 242, 242, 384, 101, 384, 244, 56, 293, 293, 364, 182, 91, 305, 132, 94, 298, 354, 94, 105, 344, 327, 327, 108, 108, 165, 197, 323, 323, 231, 333, 56, 369, 362, 362, 369, 153, 286, 133, 300, 300, 300, 104, 288, 212, 362, 331, 147, 147, 147, 147, 263, 147, 168, 55, 246, 246, 20, 175, 214, 22, 159, 138, 277, 408, 350, 58, 78, 144, 338, 225, 225, 23, 23, 379, 157, 157, 333, 310, 299, 346, 346, 192, 192, 106, 106, 298, 49, 197, 197, 310, 310, 310, 366, 366, 128, 128, 197, 372, 372, 221, 221, 123, 85, 122, 334, 263, 137, 396, 396, 51, 9, 306, 19, 185, 93, 380, 339, 339, 93, 22, 130, 82, 351, 19, 60, 60, 60, 190, 334, 154, 261, 156, 232, 326, 219, 219, 219, 46, 46, 11, 144, 335, 335, 322, 343, 232, 14, 14, 217, 195, 195, 195, 6, 193, 180, 148, 381, 381, 95, 195, 363, 50, 201, 201, 50, 266, 349, 192, 230, 318, 209, 337, 365, 365, 195, 329, 360, 398, 273, 291, 349, 349, 401, 151, 390, 390, 301, 360, 16, 118, 173, 22, 76, 138, 89, 78, 249, 359, 89, 408, 22, 160, 155, 301, 4, 301, 4, 406, 401, 348, 281, 307, 307, 229, 320, 320, 105, 105, 231, 338, 290, 290, 254, 254, 349, 155, 155, 348, 343, 156, 156, 156, 124, 116, 116, 329, 395, 355, 308, 121, 142, 142, 275, 295, 226, 385, 385, 390, 390, 244, 193, 47, 47, 186, 186, 267, 186, 158, 158, 226, 253, 253, 367, 304, 281, 183, 144, 30, 297, 1, 362, 168, 124, 131, 190, 342, 342, 342, 53, 224, 53, 53, 31, 171, 36, 326, 11, 6, 77, 161, 77, 266, 309, 37, 177, 358, 34, 361, 361, 339, 241, 241, 241, 159, 285, 15, 226, 226, 97, 83, 191, 275, 212, 189, 21, 56, 210, 3, 3, 223, 195, 363, 195, 180, 180, 180, 195, 279, 322, 81, 81, 262, 166, 100, 68, 100, 167, 315, 167, 125, 204, 204, 125, 125, 125, 109, 40, 57, 173, 173, 220, 73, 73, 304, 150, 304, 389, 101, 184, 184, 52, 228, 111, 292, 369, 111, 111, 378, 281, 270, 78, 29, 174, 29, 28, 29, 29, 29, 365, 257, 99, 143, 257, 135, 135, 260, 254, 403, 151, 403, 151, 289, 368, 157, 391, 391, 337, 354, 210, 244, 210, 293, 8, 8, 381, 381, 329, 178, 393, 241, 393, 241, 241, 280, 358, 177, 365, 402, 358, 271, 330, 65, 157, 65, 65, 243, 289, 253, 253, 61, 56, 61, 77, 132, 61, 401, 354, 244, 390, 181, 376, 279, 215, 221, 197, 122, 279, 356, 12, 148, 125, 363, 363, 363, 329, 204, 95, 204, 184, 277, 75, 367, 101, 101, 332, 58, 58, 332, 270, 299, 22, 270, 299, 362, 206, 292, 206, 251, 218, 283, 218, 251, 218, 352, 330, 330, 330, 115, 365, 115, 115, 350, 397, 285, 66, 136, 284, 366, 64, 368, 73, 73, 169, 169, 169, 169, 220, 220, 24, 220, 32, 24, 220, 362, 35, 35, 343, 80, 59, 216, 231, 231, 13, 32, 124, 13, 201, 3, 50, 201, 400, 201, 69, 69, 177, 185, 177, 177, 207, 207, 207, 109, 69, 69, 224, 289, 77, 4, 155, 301, 328, 390, 301, 64, 406, 4, 406, 157, 4, 108, 273, 372, 140, 140, 165, 165, 197, 363, 363, 204, 269, 269, 269, 269, 165, 140, 286, 286, 44, 164, 164, 116, 164, 317, 317, 130, 338, 87, 169, 291, 294, 294, 134, 134, 134, 72, 72, 400, 148, 251, 283, 324, 251, 379, 404, 216, 59, 23, 23, 340, 57, 352, 255, 255, 99, 316, 340, 284, 296, 84, 84, 366, 143, 296, 24, 319, 32, 10, 32, 229, 319, 80, 242, 24, 80, 16, 319, 405, 184, 146, 146, 347, 351, 347, 357, 80, 42, 239, 50, 134, 239, 311, 134, 18, 239, 18, 266, 316, 294, 299, 30, 94, 43, 277, 388, 109, 135, 109, 185, 185, 7, 207, 17, 328, 328, 328, 265, 106, 193, 106, 106, 193, 406, 13, 13, 13, 348, 343, 13, 404, 13, 347, 78, 196, 235, 196, 233, 203, 306, 9, 286, 323, 90, 90, 392, 90, 371, 323, 274, 338, 225, 13, 118, 205, 86, 108, 124, 161, 266, 161, 18, 77, 400, 400, 50, 266, 148, 148, 148, 148, 59, 59, 216, 103, 240, 240, 240, 240, 240, 216, 240, 240, 237, 141, 66, 135, 66, 278, 84, 258, 296, 310, 110, 74, 143, 406, 110, 302, 359, 146, 114, 405, 405, 146, 285, 118, 62, 89, 89, 89, 387, 82, 12, 245, 88, 245, 245, 36, 40, 208, 363, 208, 12, 67, 335, 67, 67, 67, 173, 183, 181, 82, 208, 181, 163, 372, 37, 382, 207, 10, 40, 373, 325, 399, 325, 88, 192, 192, 193, 298, 346, 298, 151, 346, 239, 18, 311, 311, 134, 400, 11, 266, 11, 72, 72, 9, 51, 246, 246, 51, 9, 9, 55, 196, 312, 187, 187, 187, 121, 187, 321, 187, 206, 228, 38, 169, 136, 43, 297, 297, 25, 206, 153, 148, 231, 381, 231, 394, 394, 394, 216, 357, 357, 357, 31, 381, 179, 74, 179, 156, 75, 330, 66, 278, 33, 331, 282, 282, 310, 110, 333, 110, 333, 333, 143, 405, 74, 302, 302, 114, 74, 387, 151, 17, 17, 132, 192, 250, 250, 208, 67, 68, 335, 261, 353, 250, 335, 261, 314, 262, 266, 335, 170, 215, 339, 50, 34, 361, 34, 361, 321, 241, 7, 402, 93, 290, 117, 17, 260, 346, 346, 403, 72, 95, 72, 95, 11, 6, 95, 212, 38, 196, 306, 198, 235, 312, 198, 198, 246, 20, 312, 176, 26, 321, 215, 392, 252, 252, 227, 292, 57, 238, 259, 259, 71, 71, 39, 54, 39, 39, 39, 54, 394, 360, 8, 394, 394, 178, 178, 309, 170, 30, 396, 170, 127, 170, 396, 127, 28, 28, 282, 282, 397, 282, 135, 110, 236, 33, 345, 236, 33, 191, 16, 383, 123, 16, 181, 85, 16, 376, 96, 376, 48, 353, 166, 68, 261, 250, 79, 79, 314, 36, 314, 40, 36, 36, 211, 211, 358, 393, 361, 115, 115, 361, 177, 27, 27, 27, 258, 117, 136, 136, 328, 337, 327, 337, 318, 212, 83, 375, 374, 203, 58, 375, 19, 198, 51, 9, 55, 120, 120, 104, 176, 312, 377, 377, 164, 330, 130, 70, 144, 161, 348, 400, 215, 215, 82, 351, 347, 47, 287, 137, 137, 287, 357, 357, 347, 347, 23, 103, 236, 103, 37, 37, 172, 179, 172, 172, 127, 179, 396, 287, 127, 223, 167, 28, 397, 331, 278, 256, 99, 143, 258, 325, 325, 83, 270, 356, 350, 92, 350, 353, 273, 119, 353, 119, 119, 96, 119, 336, 154, 308, 35, 35, 35, 308, 355, 355, 398, 395, 185, 352, 341, 112, 40, 93, 380, 382, 207, 284, 128, 2, 321, 2, 2, 391, 132, 385, 298, 298, 298, 266, 19, 19, 408, 306, 235, 26, 235, 268, 203, 377, 217, 195, 217, 377, 195, 223, 377, 223, 223, 223, 223, 18, 46, 11, 11, 46, 46, 14, 219, 317, 116, 116, 164, 252, 317, 317, 47, 23, 59, 59, 379, 194, 194, 194, 206, 297, 228, 362, 263, 387, 387, 405, 285, 114, 62, 118, 359, 359, 359, 62, 236, 319, 174, 174, 28, 152, 152, 102, 5, 139, 340, 99, 257, 257, 397, 387, 278, 87, 367, 75, 214, 75, 89, 75, 89, 277, 214, 214, 183, 119, 96, 119, 96, 183, 353, 287, 48, 123, 383, 42, 395, 42, 395, 355, 395, 105, 398, 93, 280, 231, 393, 34, 34, 34, 402, 40, 393, 2, 366, 296, 2, 117, 99, 99, 151, 385, 298, 265, 145, 210, 56, 235, 235, 203, 157, 224, 158, 374, 26, 311, 199, 219, 199, 199, 199, 199, 326, 219, 326, 326, 326, 14, 315, 315, 14, 167, 100, 100, 100, 100, 284, 124, 204, 158, 338, 269, 88, 370, 88, 88, 370, 370, 363, 370, 44, 44, 248, 175, 188, 380, 154, 30, 31, 31, 31, 31, 334, 319, 16, 16, 16, 80, 80, 118, 118, 24, 24, 163, 338, 267, 86, 227, 86, 102, 407, 407, 407, 305, 182, 407, 200, 182, 364, 38, 38, 274, 407, 38, 274, 227, 274, 189, 120, 189, 277, 214, 138, 277, 184, 92, 92, 92, 101, 92, 150, 384, 150, 304, 150, 123, 383, 123, 273, 273, 48, 383, 96, 221, 48, 48, 329, 42, 356, 356, 398, 329, 105, 32, 173, 37, 10, 45, 402, 34, 393, 393, 280, 241, 341, 339, 388, 331, 331, 168, 90, 318, 254, 327, 50, 265, 293, 368, 210, 293, 61, 293, 61, 289, 281, 268, 268, 268, 51, 203, 203, 374, 51, 161, 18, 161, 232, 343, 161, 18, 249, 139, 104, 139, 370, 245, 88, 245, 12, 125, 12, 208, 208, 262, 262, 68, 213, 213, 30, 30, 30, 379, 334, 313, 171, 279, 123, 85, 85, 334, 47, 291, 392, 351, 267, 392, 87, 317, 5, 364, 200, 200, 200, 364, 91, 116, 200, 87, 274, 130, 317, 87, 205, 182, 303, 270, 270, 332, 332, 350, 332, 367, 45, 389, 384, 45, 76, 76, 389, 73, 76, 45, 73, 242, 270, 73, 242, 221, 48, 221, 130, 48, 387, 387, 168, 114, 146, 62, 256, 256, 331, 256, 54, 238, 71, 39, 54, 71, 136, 401, 401, 210, 244, 128, 4, 201, 265, 289, 289, 226, 65, 97, 295, 243, 60, 268, 374, 288, 63, 375, 63, 332, 136, 375, 112, 196, 246, 139, 139, 120, 55, 86, 86, 175, 188, 31, 247, 247, 247, 247, 144, 30, 188, 164, 147, 305, 130, 215, 31, 86, 154, 79, 79, 79, 79, 273, 267, 291, 267, 267, 90, 186, 371, 91, 89, 91, 205, 303, 176, 200, 5, 305, 367, 367, 408, 408, 281, 367, 138, 92, 92, 101, 131, 73, 386, 313, 399, 399, 21, 191, 141, 172, 388, 284, 272, 272, 248, 252, 172, 114, 141, 359, 179, 62, 103, 103, 309, 71, 27, 284, 259, 160, 71, 259, 145, 290, 401, 368, 64, 260, 64, 272, 243, 271, 121, 253, 121, 121, 15, 408, 288, 60, 288, 375, 376, 372, 58, 372, 5, 86, 152, 408, 372, 306, 140, 140, 22, 144, 30, 247, 202, 379, 175, 188, 170, 175, 170, 188, 36, 36, 314, 314, 261, 314, 250, 262, 166, 261, 81, 167, 204, 315, 27, 47, 267, 398, 392, 47, 199, 139, 303, 91, 305, 120, 120, 305, 305, 5, 20, 182, 264, 206, 251, 129, 129, 129, 304, 277, 131, 43, 378, 191, 113, 190, 275, 190, 224, 190, 63, 248, 252, 248, 388, 309, 37, 37, 213, 309, 380, 211, 171, 154, 211, 211, 126, 171, 259, 238, 238, 259, 238, 259, 145, 380, 352, 257, 7, 339, 143, 254, 15, 28, 190, 373, 386, 112, 21, 123, 181, 8, 6, 6, 95, 6, 3, 294, 3, 371, 108, 371, 38, 286, 215, 300, 122, 300, 122, 188, 188, 404, 156, 363, 269, 12, 130, 215, 3, 90, 174, 338, 47, 267, 273, 111, 86, 276, 378, 297, 297, 149, 149, 264, 276, 41, 129, 234, 264, 25, 292, 356, 276, 264, 159, 275, 275, 113, 26, 158, 53, 63, 298, 248, 25, 307, 229, 163, 163, 263, 96, 171, 313, 126, 163, 30, 382, 313, 334, 334, 334, 126, 238, 237, 311, 239, 131, 194, 282, 360, 57, 15, 271, 243, 345, 296, 345, 271, 249, 112, 350, 104, 189, 399, 21, 191, 381, 8, 294, 3, 3, 336, 336, 336, 360, 336, 49, 49, 44, 44, 300, 49, 133, 49, 133, 133, 323, 256, 378, 1, 81, 167, 167, 322, 81, 315, 107, 404, 404, 404, 232, 232, 161, 14, 326, 152, 152, 205, 205, 102, 152, 102, 142, 86, 41, 234, 276, 41, 25, 25, 159, 307, 320, 307, 229, 229, 163, 273, 320, 260, 61, 403, 17, 263, 147, 344, 344, 344, 145, 354, 354, 178, 382, 126, 126, 126, 382, 266, 266, 313, 287, 137, 137, 137, 287, 340, 239, 340, 397, 360, 57, 316, 316, 237, 169, 24, 97, 389, 295, 342, 113, 365, 386, 373, 386, 249, 112, 233, 233, 21, 233, 21, 336, 294, 294, 174, 294, 162, 162, 341, 162, 341, 162, 98, 323, 291, 165, 291, 108, 140, 107, 232, 107, 107, 107, 219, 46, 217, 217, 180, 377, 180, 95, 377, 217, 294, 251, 251, 264, 264, 362, 292, 297, 205, 102, 91, 176, 364, 303, 5, 5, 152, 52, 222, 52, 362, 378, 43, 1, 378, 129, 378, 264, 153, 276, 276, 149, 276, 160, 159, 160, 272, 229, 291, 58, 265, 385, 349, 254, 64, 258, 209, 354, 209, 94, 354, 209, 327, 327, 287, 351, 357, 70, 70, 183, 82, 225, 225, 70, 128, 201, 316, 128, 117, 318, 337, 321, 97, 97, 135, 92, 142, 138, 295, 295, 399, 212, 83, 112, 83, 83, 249, 212, 162, 98, 162, 341, 98, 98, 98, 352, 341, 98, 7, 309, 195, 363, 18, 107, 166, 315, 315, 355, 322, 166, 166, 322, 322, 315, 68, 68, 81, 60, 26, 333, 263, 168, 136, 1, 288, 373, 369, 222, 222, 222, 222, 228, 52, 228, 111, 251, 234, 264, 149, 41, 149, 149, 43, 227, 299, 78, 281, 299, 278, 66, 255, 255, 99, 255, 282, 237, 64, 17, 319, 258, 318, 64, 349, 254, 344, 209, 391, 230, 230, 230, 328, 225, 183, 213, 77, 103, 309, 213, 213, 178, 178, 202, 394, 202, 202, 202, 202, 136, 136, 117, 290, 280, 402], {1: [2174, 2274, 351, 2025], 2: [1236, 1361, 1233, 1235, 1364], 3: [609, 1924, 1902, 399, 400, 2006, 1904, 2005], 4: [286, 640, 288, 629, 1652, 637], 5: [2165, 1312, 2166, 1786, 1718, 1835, 1586], 6: [1899, 234, 1019, 1901, 1898, 369], 7: [1004, 752, 51, 2249, 49, 50, 59, 1884], 8: [2003, 1056, 484, 485, 1897], 9: [781, 192, 913, 1139, 907, 912], 10: [58, 1504, 881, 709, 60, 47], 11: [221, 368, 1267, 1268, 902, 904, 1018], 12: [1556, 1921, 530, 854, 1558, 864], 13: [772, 793, 604, 765, 766, 767, 770, 607], 14: [1395, 228, 1398, 2039, 1271, 229], 15: [387, 1888, 1776, 1987], 16: [270, 1432, 1434, 1090, 717, 1433, 1084, 1087], 17: [1009, 2308, 975, 976, 754, 2068], 18: [1542, 737, 802, 1265, 897, 735, 1547, 2253], 19: [1244, 1136, 194, 205, 1245], 20: [138, 4, 1031, 1836], 21: [396, 2000, 2115, 2117, 1894, 1736], 22: [53, 54, 61, 1794, 552, 141, 273, 55, 201, 282], 23: [153, 1281, 689, 690, 1170, 154], 24: [593, 1440, 706, 2101, 590, 715, 1439], 25: [1, 1960, 932, 2055, 2054, 1945], 26: [6, 1954, 1034, 2269, 1382, 1249], 27: [1820, 1117, 1118, 1119, 1756], 28: [1071, 1070, 1889, 1187, 456, 1308], 29: [457, 453, 455, 458, 459], 30: [1796, 1568, 1971, 1063, 349, 742, 1689, 1567, 1566, 1425], 31: [1428, 1696, 1427, 1683, 1429, 364, 946, 1426], 32: [708, 592, 605, 710, 1501], 33: [1082, 1079, 26, 956], 34: [1356, 1507, 1000, 1355, 1357, 998, 378], 35: [596, 1216, 597, 22, 1214, 1215], 36: [366, 1106, 1807, 1107, 1103, 1806, 859], 37: [1863, 1862, 878, 375, 1503, 1175, 1174], 38: [1457, 1458, 926, 1908, 1022, 14, 1461], 39: [1048, 1643, 1050, 1051, 1052], 40: [1226, 1105, 1359, 882, 860, 428], 41: [2290, 2050, 2053, 1941], 42: [1345, 728, 1343, 1495], 43: [2293, 1847, 744, 929, 2173], 44: [1419, 1418, 660, 2015, 2014], 45: [1619, 1505, 1610, 1613, 77], 46: [1270, 219, 220, 1266, 1269, 2142], 47: [334, 1280, 1825, 1578, 333, 1928, 1821, 1161], 48: [1493, 1094, 1626, 1629, 1488, 1340, 1492], 49: [2017, 168, 2012, 2013, 2019], 50: [997, 610, 806, 1522, 243, 246, 730], 51: [908, 1138, 911, 1540, 1536, 191], 52: [442, 2283, 2168, 2170], 53: [360, 1956, 363, 362], 54: [1049, 1640, 1644, 1053], 55: [914, 1140, 135, 1678], 56: [88, 397, 1374, 112, 512], 57: [429, 2096, 1986, 1042, 692], 58: [2190, 147, 547, 1784, 548, 1134], 59: [812, 688, 600, 813, 1282, 1283], 60: [1779, 208, 2268, 207, 1662, 206], 61: [511, 513, 2066, 1528, 1530, 516], 62: [848, 1635, 1751, 1303, 1298], 63: [1957, 1666, 1668, 1856], 64: [2312, 635, 2195, 2307, 1766, 1768, 580], 65: [506, 505, 503, 24, 1658], 66: [954, 828, 2300, 576, 826], 67: [869, 865, 867, 868, 982], 68: [1563, 416, 2265, 983, 1097, 2266], 69: [614, 624, 625, 615], 70: [2208, 2209, 1151, 2214], 71: [1760, 1046, 1642, 1755, 1645, 1047], 72: [677, 678, 1014, 1016, 905, 906], 73: [433, 1617, 434, 1620, 582, 1731, 52, 1623, 583], 74: [972, 968, 835, 949, 38], 75: [952, 1323, 1325, 1327, 542], 76: [78, 76, 1614, 79, 274, 1618, 1615], 77: [514, 370, 628, 2325, 372, 803], 78: [2296, 452, 148, 774, 63, 277], 79: [1100, 1700, 1699, 1701, 1702, 1101], 80: [1436, 599, 727, 1435, 716, 713], 81: [2267, 2030, 412, 2026, 1816, 411], 82: [873, 2211, 1158, 203, 853], 83: [2233, 1130, 1197, 391, 2235, 2236], 84: [701, 830, 702], 85: [1575, 1089, 184, 1576], 86: [1679, 1444, 796, 1932, 1697, 1446, 2049, 1680, 1787], 87: [1599, 669, 1321, 1595, 1584], 88: [1413, 1410, 1412, 1554, 887, 856], 89: [1326, 1712, 1328, 849, 850, 851, 276, 280], 90: [1518, 784, 785, 787, 1925, 1708], 91: [1711, 2161, 1713, 93, 1829, 1592], 92: [1474, 1728, 1201, 2226, 1475, 1473, 1477, 1727], 93: [1006, 196, 1351, 200, 1227], 94: [743, 96, 99, 2200], 95: [240, 2148, 1015, 1900, 1017, 538, 1020], 96: [1966, 1209, 1334, 1336, 1490, 1092], 97: [2223, 2224, 390, 2102, 1659], 98: [2248, 2240, 2129, 2243, 2244, 2245], 99: [462, 1315, 696, 1367, 1192, 1366, 2303], 100: [417, 1400, 1403, 415, 1401, 1402], 101: [1476, 439, 545, 544, 1729, 85], 102: [2045, 2047, 75, 1311, 2160, 1447], 103: [815, 2326, 1753, 1752, 1171, 1173], 104: [1550, 1143, 12, 123, 1997], 105: [299, 298, 1349, 100, 1500], 106: [165, 761, 166, 759, 762], 107: [2138, 2139, 2140, 2254, 2032, 2136], 108: [797, 1906, 2134, 104, 105, 641], 109: [747, 623, 427, 749], 110: [1077, 834, 963, 838, 961], 111: [444, 448, 69, 70, 447, 2285, 1931], 112: [1995, 1893, 1672, 1225, 2112, 2234], 113: [1850, 8, 9, 1953, 2106], 114: [842, 1633, 971, 1297, 1747], 115: [569, 1114, 571, 572, 1113], 116: [1593, 663, 1275, 1274, 315, 316], 117: [1121, 1008, 1365, 2219, 2340], 118: [1438, 45, 794, 44, 1437, 46, 271, 847, 1299], 119: [1207, 1210, 1333, 1205, 1335, 1208], 120: [1831, 1142, 1832, 1466, 1677, 1141], 121: [1772, 1774, 1775, 321, 920], 122: [185, 1912, 527, 1914], 123: [1895, 183, 1341, 1086, 1574, 1483, 1485], 124: [314, 354, 1405, 606, 798], 125: [425, 424, 421, 426, 532, 1557], 126: [1977, 2080, 2081, 1872, 1969, 2079], 127: [1066, 1184, 1069, 1180], 128: [1232, 176, 177, 1651, 2215, 2218], 129: [1842, 2176, 1841, 1843, 1942], 130: [1597, 1694, 65, 1922, 1150, 202, 667, 1628], 131: [355, 0, 1730, 1982, 1846], 132: [95, 977, 515, 1238], 133: [2018, 2020, 2021, 119], 134: [734, 676, 731, 674, 675, 900], 135: [465, 2225, 466, 748, 1076, 827], 136: [2273, 928, 1122, 1670, 577, 2339, 1123, 1646, 2338], 137: [2088, 2087, 2089, 188, 1163, 1164], 138: [143, 275, 2228, 1470, 1726], 139: [1675, 1313, 1549, 1551, 1827, 1676], 140: [645, 1792, 1793, 644, 2135, 657], 141: [16, 825, 1748, 15, 1738], 142: [323, 2048, 322, 2227, 7, 73], 143: [966, 836, 1193, 29, 1886, 463, 704], 144: [222, 1795, 149, 1688, 348, 1152], 145: [2074, 1762, 1880, 1372], 146: [722, 721, 841, 1634, 845], 147: [130, 129, 131, 1692, 128, 133, 2070], 148: [811, 809, 935, 808, 810, 680, 531, 237], 149: [1938, 2289, 2291, 2182, 2292, 1937], 150: [81, 80, 436, 1478, 1480, 1482], 151: [265, 470, 472, 974, 894, 1368], 152: [2042, 1788, 1309, 2046, 2167, 2041, 1310], 153: [30, 2179, 117, 32, 934], 154: [1698, 1424, 211, 1212, 1869], 155: [308, 307, 284, 630], 156: [213, 311, 313, 1918, 312, 951], 157: [475, 1378, 156, 157, 639, 504], 158: [1955, 339, 1380, 340, 1407], 159: [142, 385, 1950, 2056, 2185], 160: [1759, 283, 23, 2184, 2186], 161: [1543, 801, 1153, 1541, 2038, 1546, 799, 371], 162: [2123, 2126, 2124, 2239, 2241, 2128], 163: [1963, 1964, 2062, 1970, 876, 1441], 164: [64, 1276, 662, 661, 1691, 1148, 664], 165: [2132, 646, 647, 106, 656], 166: [2255, 2260, 2261, 414, 1096, 1814], 167: [2028, 1186, 1399, 2027, 1817, 418, 420], 168: [1517, 2272, 134, 1632, 353], 169: [586, 584, 927, 2100, 585, 587, 670], 170: [1067, 994, 1062, 1065, 1802, 1804], 171: [1967, 1572, 1868, 365, 1873], 172: [19, 18, 40, 1178, 1739, 1179, 1746, 17, 1176], 173: [870, 272, 1502, 430, 431, 48], 174: [1926, 2121, 454, 1306, 1307], 175: [1421, 1681, 1803, 139, 1800], 176: [2162, 3, 1716, 1144, 1033], 177: [497, 376, 618, 619, 616, 1116], 178: [1059, 2077, 1060, 489, 2330, 2331], 179: [950, 1750, 1181, 948, 1177], 180: [405, 406, 407, 236, 2145, 2147], 181: [521, 1088, 872, 1896, 875], 182: [92, 1601, 1452, 1455, 1837], 183: [2323, 2210, 1332, 871, 347, 1337], 184: [1472, 440, 441, 540, 720], 185: [751, 195, 617, 750, 1222], 186: [335, 336, 338, 1709], 187: [917, 918, 921, 919, 923], 188: [1682, 1801, 1690, 1422, 1915, 1805, 1916], 189: [1465, 1998, 1467, 395], 190: [356, 1890, 1851, 1853, 1855, 209, 5], 191: [1737, 2001, 1849, 1083, 392], 192: [164, 163, 978, 888, 889, 249], 193: [760, 890, 235, 332, 763], 194: [1287, 1285, 1286, 1983], 195: [231, 241, 402, 404, 232, 1258, 256, 233, 1255, 408, 2251], 196: [1673, 915, 1023, 777, 775], 197: [170, 178, 648, 169, 526, 107], 198: [1025, 1137, 1028, 1029], 199: [1384, 1388, 1386, 1387, 1389, 1826], 200: [1717, 1588, 1589, 1590, 1594, 1454], 201: [245, 608, 244, 611, 1653, 613, 2216], 202: [2337, 2336, 2335, 2334, 2332, 1798], 203: [1133, 1537, 1538, 1377, 1252, 779], 204: [1406, 422, 423, 537, 1818, 651, 539], 205: [2044, 1600, 795, 2159, 1714, 2043], 206: [924, 1288, 556, 933, 558, 1839], 207: [753, 620, 621, 622, 880, 1230], 208: [1559, 1560, 874, 981, 863, 861], 209: [2316, 2197, 2199, 2202, 252], 210: [398, 480, 1649, 482, 1526, 1373], 211: [1871, 1867, 1870, 1108, 1109], 212: [1129, 394, 1021, 125, 2232, 2238], 213: [2329, 2324, 2328, 1864, 1564, 1565], 214: [1469, 140, 1330, 1331, 1324], 215: [1036, 995, 1156, 524, 1695, 1923, 1157, 1910], 216: [821, 942, 814, 687, 601], 217: [2143, 2144, 2150, 230, 1256, 1254], 218: [67, 560, 66, 562, 564], 219: [217, 1385, 1272, 218, 2141, 216, 1391], 220: [432, 588, 589, 591, 594], 221: [525, 1491, 182, 1625, 1627, 181], 222: [2278, 2279, 2280, 2281, 2169], 223: [1262, 1261, 1263, 1264, 1259, 1185, 401], 224: [1854, 626, 1379, 361], 225: [2322, 2213, 2212, 151, 152, 792], 226: [1657, 388, 389, 326, 341], 227: [1040, 1445, 2294, 1463], 228: [443, 71, 1290, 2282, 2284, 925], 229: [2060, 711, 295, 1962, 2188, 2061], 230: [2319, 2320, 250, 2318], 231: [1353, 936, 300, 110, 602, 603, 938], 232: [2037, 227, 2036, 214, 1544, 2137], 233: [2116, 2113, 2114, 778], 234: [2051, 1943, 2287], 235: [1026, 776, 1248, 1376, 1250, 1375], 236: [43, 1304, 1078, 1081, 1172], 237: [2099, 824, 1979, 2306], 238: [1875, 1978, 1043, 1876, 1878, 1641], 239: [732, 736, 2092, 729, 1981, 896], 240: [819, 816, 817, 818, 820, 823, 822], 241: [494, 382, 1003, 493, 383, 384, 491, 1511], 242: [1624, 82, 714, 83, 1621], 243: [1661, 1989, 1770, 507], 244: [1650, 481, 519, 331, 87], 245: [1555, 857, 855, 1553, 858], 246: [909, 1030, 136, 137, 910, 1674], 247: [1684, 1797, 1686, 1687, 1685], 248: [1859, 1744, 1857, 1959, 1420], 249: [13, 278, 1548, 2111, 2237, 1994], 250: [979, 980, 1812, 987, 1099], 251: [2153, 2152, 2286, 1840, 563, 681, 559, 684], 252: [1038, 1745, 1277, 1858, 1039], 253: [510, 342, 343, 509, 1773], 254: [468, 304, 305, 1520, 2194, 2314, 1887], 255: [2302, 2304, 27, 694, 695, 2301], 256: [1637, 1636, 1639, 39, 2023, 1191], 257: [1883, 1316, 461, 464, 1317], 258: [2310, 1120, 831, 2196, 1194], 259: [1874, 1761, 1758, 1045, 1877, 1044, 1879], 260: [2065, 1010, 467, 1767], 261: [985, 1810, 212, 1098, 989, 1815], 262: [1562, 1813, 1561, 413, 991], 263: [132, 187, 1292, 2069, 2271, 1965], 264: [1939, 2288, 2178, 2154, 2155, 1838, 31, 1944, 1949], 265: [2191, 1523, 758, 1654, 1371], 266: [2083, 800, 992, 738, 2084, 903, 1243, 807, 373, 247], 267: [337, 1929, 1822, 1443, 1706, 1707, 1582, 1704], 268: [1533, 1251, 1535, 1663, 1534], 269: [653, 1920, 1409, 652, 654, 655], 270: [1198, 451, 1604, 553, 1603, 550, 1622], 271: [1771, 1988, 501, 1993], 272: [1742, 1769, 2187, 1743], 273: [1703, 642, 260, 1487, 1204, 1930, 1486, 2063], 274: [790, 1459, 1462, 1464, 1596], 275: [11, 1952, 393, 324, 10, 1951, 1852], 276: [2181, 2180, 2052, 1940, 2183, 1948, 1933], 277: [1845, 144, 745, 541, 1329, 1468, 1471], 278: [2299, 1190, 1320, 829, 955], 279: [1573, 409, 523, 528], 280: [1510, 2342, 495, 1352], 281: [2297, 450, 292, 1724, 346, 1532], 282: [1072, 1073, 1075, 958, 959, 1984, 2305], 283: [561, 682, 37, 36, 33], 284: [1404, 578, 1757, 699, 1231, 1741], 285: [20, 41, 846, 575, 1296, 386], 286: [1909, 782, 659, 118, 658], 287: [2086, 2090, 1339, 2205, 1162, 1165, 1183], 288: [1780, 1778, 124, 1665, 2275], 289: [1655, 627, 1656, 1531, 508, 473], 290: [1763, 2341, 302, 303, 1007], 291: [671, 261, 2133, 1705, 1579, 2189, 2131], 292: [1041, 557, 1946, 2157, 445], 293: [1527, 483, 1524, 89, 90, 1529], 294: [740, 672, 673, 2119, 1903, 2120, 2004, 2122, 2151], 295: [2230, 1660, 325, 2229, 2104], 296: [705, 832, 1363, 1991, 700], 297: [931, 1936, 930, 350, 1935, 2158, 1289], 298: [97, 1958, 167, 893, 1241, 1370, 1242, 891, 1240], 299: [2295, 160, 741, 551, 2298, 554], 300: [120, 2016, 121, 1913, 122, 1911], 301: [287, 268, 631, 634, 285], 302: [839, 969, 970, 42], 303: [2164, 1602, 1828, 1715], 304: [435, 437, 1844, 1481, 345], 305: [1719, 2, 1830, 1834, 1693, 1833, 1451, 94], 306: [1791, 1024, 193, 780, 1247], 307: [294, 293, 1961, 2059, 2057], 308: [320, 1217, 21, 1213], 309: [2327, 374, 1865, 1061, 2250, 1754, 1861], 310: [173, 960, 172, 833, 171, 159], 311: [1383, 898, 899, 1980, 733], 312: [1032, 1145, 1027, 916], 313: [1973, 1968, 1571, 1733, 2085], 314: [990, 1104, 1808, 1102, 1809, 1811], 315: [419, 1819, 2257, 2264, 2256, 1396, 1397, 2031], 316: [2217, 2098, 739, 2097, 697], 317: [1273, 1585, 1278, 665, 1598, 1279, 666], 318: [251, 1519, 1128, 2311, 2220], 319: [712, 707, 1431, 1305, 2309, 718], 320: [2058, 2064, 296, 297], 321: [2222, 1002, 922, 1035, 1234], 322: [2262, 225, 2259, 2263, 410, 2029], 323: [2130, 789, 2022, 108, 109, 783], 324: [683, 34, 35, 68], 325: [884, 1195, 886, 1196], 326: [215, 2040, 1393, 1394, 1390, 367, 1392], 327: [102, 1521, 1126, 103, 2204, 2203], 328: [755, 2321, 756, 632, 757, 1124], 329: [536, 488, 1494, 1499, 257, 317], 330: [953, 566, 567, 568, 502, 1149], 331: [1189, 1638, 957, 1516, 1515, 127], 332: [1669, 546, 549, 1605, 1606, 1608], 333: [964, 962, 965, 158, 111, 2270], 334: [1430, 210, 1975, 1974, 1976, 186, 1577, 1570], 335: [984, 993, 224, 223, 866, 988], 336: [2007, 2118, 2008, 2009, 2011, 1211], 337: [478, 2221, 1127, 253, 1125], 338: [1408, 1442, 1927, 668, 791, 301, 150], 339: [381, 996, 198, 1513, 1885, 199], 340: [57, 2091, 1314, 2093, 691, 698], 341: [1224, 2242, 1512, 2247, 2125, 2127], 342: [359, 2105, 357, 358], 343: [226, 310, 598, 1545, 769], 344: [2072, 2071, 101, 2073, 2315], 345: [25, 1990, 1992, 1080, 28], 346: [895, 1011, 1012, 892, 162, 161], 347: [1160, 723, 725, 1168, 773, 1169], 348: [309, 768, 1154, 291], 349: [306, 2193, 263, 248, 262, 2313], 350: [1996, 1200, 146, 1607, 573, 62, 1202], 351: [1159, 1581, 2206, 724, 204], 352: [565, 693, 2246, 1223, 1882], 353: [1203, 1206, 1095, 986, 1338], 354: [98, 518, 2075, 2076, 2198, 479, 2201], 355: [1218, 2258, 1347, 1219, 319], 356: [529, 1496, 1497, 1947, 1199], 357: [945, 944, 726, 1167, 943, 1166, 2207], 358: [500, 496, 1110, 377], 359: [1301, 1300, 1302, 279, 840, 1749], 360: [1055, 2010, 269, 2095, 1985, 258], 361: [380, 379, 999, 1001, 1112, 1115], 362: [114, 1291, 595, 115, 2171, 352, 555, 126, 2156], 363: [534, 649, 650, 533, 535, 1919, 1416, 862, 403, 242, 2252], 364: [91, 2163, 1591, 1456, 1587], 365: [2107, 498, 254, 255, 570, 460], 366: [579, 1362, 174, 175, 703], 367: [1720, 1721, 344, 1609, 1322, 543, 1725], 368: [1765, 581, 1525, 474], 369: [116, 113, 72, 446, 2277], 370: [1415, 1552, 1411, 1414, 1417], 371: [1710, 788, 1907, 1905], 372: [180, 179, 1783, 1785, 643, 877, 1790], 373: [2109, 1891, 883, 2276], 374: [1539, 1664, 1381, 1132], 375: [1135, 1667, 1131, 1671, 1781], 376: [1093, 1091, 1782, 522], 377: [1257, 2146, 1147, 1146, 1260, 1253, 2149], 378: [2177, 2024, 2175, 1848, 449, 1934, 2172], 379: [155, 1284, 1799, 685, 1569], 380: [1881, 197, 1866, 1228, 1423], 381: [937, 239, 947, 486, 487, 238, 2002], 382: [2082, 1972, 2078, 879, 1229], 383: [1342, 1489, 1484, 1085], 384: [1479, 84, 86, 56, 1612], 385: [2192, 1239, 327, 1369, 328], 386: [1732, 1892, 2108, 2110], 387: [1319, 852, 1293, 1630, 1631, 973, 1294], 388: [74, 1860, 1514, 746, 1740], 389: [1611, 1616, 438, 2103], 390: [520, 329, 633, 330, 267, 266], 391: [1237, 2317, 476, 477], 392: [1583, 1824, 786, 1580, 1037], 393: [1360, 1508, 1111, 490, 492, 1354, 1509], 394: [940, 1058, 939, 941, 1054, 1057, 2333], 395: [318, 1344, 1346, 1348, 1221], 396: [1068, 1064, 190, 189, 1182], 397: [1074, 574, 2094, 1188, 1318], 398: [259, 1220, 1350, 1498, 1823], 399: [1735, 1734, 1999, 2231, 885], 400: [804, 1155, 612, 901, 805, 679], 401: [1647, 1648, 290, 1764, 517, 264], 402: [2343, 1506, 499, 1005, 1358], 403: [471, 469, 2067, 1013], 404: [2035, 2033, 2034, 771, 1917, 686], 405: [843, 844, 719, 967, 1295], 406: [289, 764, 636, 638, 837], 407: [1453, 1460, 1448, 1450, 1449], 408: [281, 145, 1777, 1722, 1723, 1246, 1789]}, {1: 20214, 2: 23440, 3: 32915, 4: 28258, 5: 31039, 6: 20104, 7: 24392, 8: 20544, 9: 24401, 10: 23641, 11: 22938, 12: 26249, 13: 30179, 14: 22179, 15: 20621, 16: 31570, 17: 25563, 18: 27519, 19: 21980, 20: 21768, 21: 22225, 22: 26064, 23: 21440, 24: 26981, 25: 21654, 26: 21405, 27: 21404, 28: 23782, 29: 21176, 30: 27804, 31: 27933, 32: 21111, 33: 20368, 34: 24992, 35: 22412, 36: 26046, 37: 30146, 38: 24137, 39: 21294, 40: 22818, 41: 21022, 42: 20394, 43: 24004, 44: 23750, 45: 23089, 46: 20958, 47: 29597, 48: 26632, 49: 24677, 50: 23226, 51: 30378, 52: 21852, 53: 20303, 54: 23157, 55: 22187, 56: 29079, 57: 23176, 58: 22639, 59: 21360, 60: 23280, 61: 21860, 62: 24132, 63: 20050, 64: 25136, 65: 27402, 66: 23449, 67: 20416, 68: 22765, 69: 20985, 70: 23043, 71: 22963, 72: 25206, 73: 34382, 74: 20321, 75: 22559, 76: 25392, 77: 20584, 78: 29595, 79: 20753, 80: 27779, 81: 23243, 82: 28194, 83: 28833, 84: 20308, 85: 22121, 86: 29397, 87: 20571, 88: 23543, 89: 25408, 90: 27343, 91: 24744, 92: 39349, 93: 23198, 94: 21502, 95: 22393, 96: 24645, 97: 27303, 98: 21181, 99: 35632, 100: 23596, 101: 22161, 102: 22695, 103: 22253, 104: 22710, 105: 22113, 106: 27046, 107: 28134, 108: 29200, 109: 24896, 110: 20704, 111: 43599, 112: 31582, 113: 31023, 114: 20494, 115: 22559, 116: 28930, 117: 25032, 118: 28870, 119: 26244, 120: 27007, 121: 23916, 122: 24267, 123: 27041, 124: 24556, 125: 26321, 126: 26836, 127: 20319, 128: 25290, 129: 23969, 130: 22171, 131: 23715, 132: 22757, 133: 21111, 134: 20460, 135: 23583, 136: 33997, 137: 21260, 138: 22017, 139: 22411, 140: 23540, 141: 20584, 142: 22842, 143: 23742, 144: 21184, 145: 20622, 146: 24644, 147: 20762, 148: 23884, 149: 27064, 150: 23924, 151: 27637, 152: 22687, 153: 20315, 154: 20964, 155: 20796, 156: 25699, 157: 21811, 158: 25427, 159: 21732, 160: 25625, 161: 20544, 162: 23438, 163: 21145, 164: 22122, 165: 20043, 166: 23183, 167: 22847, 168: 29729, 169: 21587, 170: 22071, 171: 24179, 172: 30204, 173: 21435, 174: 22700, 175: 23047, 176: 20676, 177: 26407, 178: 24705, 179: 21530, 180: 22420, 181: 20107, 182: 22601, 183: 26134, 184: 20104, 185: 23419, 186: 22163, 187: 22017, 188: 24211, 189: 20495, 190: 30479, 191: 22040, 192: 27844, 193: 20765, 194: 21377, 195: 30622, 196: 26582, 197: 23454, 198: 21603, 199: 21471, 200: 27396, 201: 23701, 202: 23461, 203: 28677, 204: 23012, 205: 21207, 206: 22943, 207: 20330, 208: 32204, 209: 20269, 210: 25934, 211: 24312, 212: 26242, 213: 22034, 214: 23234, 215: 22487, 216: 22926, 217: 21285, 218: 24570, 219: 21217, 220: 20989, 221: 25080, 222: 22139, 223: 20700, 224: 24104, 225: 26532, 226: 21517, 227: 21846, 228: 20802, 229: 21753, 230: 21788, 231: 25597, 232: 21491, 233: 20967, 234: 20095, 235: 28812, 236: 20005, 237: 20867, 238: 21074, 239: 23183, 240: 26295, 241: 27085, 242: 20260, 243: 22453, 244: 21140, 245: 21006, 246: 27017, 247: 20368, 248: 23305, 249: 26385, 250: 21113, 251: 23084, 252: 24335, 253: 22540, 254: 27781, 255: 25618, 256: 22204, 257: 26657, 258: 20009, 259: 29486, 260: 21998, 261: 25428, 262: 21513, 263: 25926, 264: 20505, 265: 23512, 266: 32570, 267: 28310, 268: 24658, 269: 24234, 270: 22522, 271: 20808, 272: 23410, 273: 25877, 274: 22680, 275: 32350, 276: 20829, 277: 20069, 278: 20894, 279: 23203, 280: 20792, 281: 23986, 282: 23607, 283: 23222, 284: 30943, 285: 25014, 286: 25682, 287: 23174, 288: 22308, 289: 25485, 290: 27296, 291: 24533, 292: 25963, 293: 27314, 294: 30237, 295: 25157, 296: 23287, 297: 26228, 298: 25066, 299: 25832, 300: 20981, 301: 22919, 302: 20311, 303: 20232, 304: 21386, 305: 23705, 306: 20007, 307: 22535, 308: 20656, 309: 22127, 310: 25445, 311: 20445, 312: 20933, 313: 20907, 314: 21410, 315: 27517, 316: 21134, 317: 23828, 318: 21086, 319: 21384, 320: 22491, 321: 20174, 322: 25965, 323: 27656, 324: 23019, 325: 20270, 326: 23549, 327: 27090, 328: 31718, 329: 26220, 330: 23622, 331: 24930, 332: 24685, 333: 25007, 334: 27725, 335: 26584, 336: 22182, 337: 23600, 338: 25337, 339: 25263, 340: 23463, 341: 21310, 342: 20648, 343: 20279, 344: 21207, 345: 21604, 346: 31551, 347: 21122, 348: 21053, 349: 22597, 350: 22251, 351: 20219, 352: 22711, 353: 22525, 354: 24327, 355: 20627, 356: 24829, 357: 23500, 358: 20120, 359: 21343, 360: 25421, 361: 23854, 362: 37538, 363: 31239, 364: 24808, 365: 23786, 366: 23291, 367: 30921, 368: 22297, 369: 23901, 370: 20779, 371: 24715, 372: 25740, 373: 21446, 374: 21149, 375: 21459, 376: 24266, 377: 24638, 378: 26366, 379: 22611, 380: 23736, 381: 23027, 382: 23269, 383: 23538, 384: 21128, 385: 22060, 386: 22150, 387: 29492, 388: 21355, 389: 20570, 390: 21675, 391: 22515, 392: 21566, 393: 21238, 394: 22751, 395: 24032, 396: 22933, 397: 20950, 398: 23747, 399: 28803, 400: 20225, 401: 26790, 402: 22288, 403: 22697, 404: 21257, 405: 22086, 406: 20564, 407: 21032, 408: 20792}]])\n"
     ]
    }
   ],
   "source": [
    "print(iterated_greedy_construction(arr,\n",
    "    attr,  # noqa ARG001\n",
    "    #deconstruct_areas,\n",
    "    threshold_array,\n",
    "    distance_matrix,\n",
    "    w,\n",
    "    sum_low,\n",
    "    top_n,\n",
    "    initial_it = 1,\n",
    "    deconstruct_it = 1000,\n",
    "    reconst_it = 99,\n",
    "    disturbance_intensity = 0.05,\n",
    "    max_it=1,\n",
    "    verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404   41.89947271347046\n",
      "402   42.97756052017212\n",
      "393   38.961400747299194\n",
      "403   73.61004281044006\n",
      "403   39.85603857040405\n",
      "411   78.42442584037781\n",
      "404   39.92354774475098\n",
      "405   37.649874448776245\n",
      "406   42.190765380859375\n"
     ]
    }
   ],
   "source": [
    "top_n = 2\n",
    "sum_attr = 'pop2010'\n",
    "sum_low = 20000.0\n",
    "dis_attr = 'households'\n",
    "#RANDOM_SEED = 123456\n",
    "#numpy.random.seed(RANDOM_SEED)\n",
    "for di in range(1, 10):\n",
    "    start_time = time.time()\n",
    "    model = MaxPHeuristic_IG(lacity, w, dis_attr, sum_attr, sum_low, top_n, verbose = False, initial_it = 1,\n",
    "        deconstruct_it = 1000,\n",
    "        reconst_it = 99,\n",
    "        disturbance_intensity = di/100,\n",
    "        max_it=1, tarjan_flag = True)\n",
    "    model.solve()\n",
    "    print(model.p, \" \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import libpysal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import spopt\n",
    "from spopt.region import MaxPHeuristic_IG as MaxP_IG\n",
    "\n",
    "RANDOM_SEED = 123456\n",
    "\n",
    "%watermark -w\n",
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
